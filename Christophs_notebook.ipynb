{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amazing-registration",
   "metadata": {},
   "source": [
    "*for more information, checkout* [Github](https://github.com/Crazytoph/2Dcorrelation \"my github page\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-electron",
   "metadata": {},
   "source": [
    "**CD Measurements - Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-defense",
   "metadata": {},
   "source": [
    "# DNA Origami "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-jefferson",
   "metadata": {},
   "source": [
    "## *setting up the Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "framed-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "import openpyxl\n",
    "import re\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-bristol",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "theoretical-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "timely-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# activate Latex, change font type\\nplt.rcParams.update({\\n    \"text.usetex\": True,\\n    \"font.family\": \"sans-serif\",\\n    \"font.serif\": [\"Helvetica\"],\\n})'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "\"\"\"# activate Latex, change font type\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.serif\": [\"Helvetica\"],\n",
    "})\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-piece",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "focal-spine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 M Control 10 mM Mg', '05 M Gdm2SO4 100 mM Mg', '05 M Gdm2SO4 400 mM Mg', '1 M GdmCl 100 mM Mg', '1 M GdmCl 400 mM Mg', '1 M GdmCl 400 mM Mg 2', '2 M Gdm2SO4 100 mM Mg', '2 M Gdm2SO4 400 mM Mg', '4 M GdmCl', '4 M GdmCl 100 mM Mg', '4 M GdmCl 100 mM Mg 2', '4 M GdmCl 400 mM Mg']\n"
     ]
    }
   ],
   "source": [
    "# Path for Daniel:\n",
    "#path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "path = \"F:\\\\HZDR\\\\0_Cloud\\\\CD_Jasco_815\\\\DNA\\Origami\\\\Triangle\\\\1-99_Denaturation\"\n",
    "\n",
    "# My Path:\n",
    "#path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\DNA Origami\"\n",
    "#path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\1-99_Denaturation\"\n",
    "datalist = os.listdir(path)\n",
    "print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outdoor-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_all = {}\n",
    "for i in range(len(datalist)):\n",
    "    data_all[datalist[i]] = cdata.CData(os.path.join(path, datalist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "municipal-college",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cdata.CData object at 0x000001FBE0CA0880>\n",
      "[<cdata.CData object at 0x000001FBE0CA0880>, <cdata.CData object at 0x000001FBE0C89C70>]\n",
      "(<cdata.CData object at 0x000001FBE0CA0880>, <cdata.CData object at 0x000001FBE0BB1880>, <cdata.CData object at 0x000001FBE0CFFA00>, <cdata.CData object at 0x000001FBE0D28070>)\n"
     ]
    }
   ],
   "source": [
    "# options to acces data\n",
    "print(data_all['0 M Control 10 mM Mg'])\n",
    "# multiple options\n",
    "print(list(map(data_all.get, ['0 M Control 10 mM Mg', '4 M GdmCl'])))\n",
    "print(tuple(data_all.values())[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-sleeve",
   "metadata": {},
   "source": [
    "## Smooth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "irish-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_smooth = {}\n",
    "for key in data_all.keys():\n",
    "\n",
    "    \n",
    "    window_size = 5\n",
    "    tail = window_size // 2\n",
    "    df = data_all[key].cd_df\n",
    "    df_new = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for i in range(tail, len(df.columns[tail:-tail])+1): \n",
    "        df_new[df.columns[i]] = df.iloc[:, i]\n",
    "        \n",
    "        for k in range(1, tail+1):\n",
    "            df_new[df.columns[i]] = df_new[df.columns[i]] + df.iloc[:, i-k] + df.iloc[:, i+k]\n",
    "        \n",
    "        df_new[df.columns[i]] = df_new[df.columns[i]] / window_size\n",
    "    data_all_smooth[key] = df_new\n",
    "    \n",
    "    #if printed\n",
    "    #print_path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "    #name = os.path.join(print_path, key + '_smoothed.txt')\n",
    "    #df_new.to_csv(name, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-continent",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-secret",
   "metadata": {},
   "source": [
    "### Print-out for PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-tennis",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Creates the .dat - files which are used for PCA and ITTFA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "armed-administration",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Control_0M'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-369812322fe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Control_0M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'Control_0M'"
     ]
    }
   ],
   "source": [
    "print(data_all['Control_0M'].t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general path where files should be saved without last folder name\n",
    "\n",
    "# Daniels path\n",
    "print_path = \"F:\\\\HZDR\\\\0_Cloud\\\\ITTFA_PCA\\\\dat\"\n",
    "# Christophs path\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Control_0M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files get seperatedly created, folder name must exist\n",
    "folder_name = 'Control_0M'\n",
    "i= 1\n",
    "\n",
    "for key in liste:\n",
    "    for col in data_all[key].cd_df.columns:\n",
    "        if col >= 20  and col <= 90:\n",
    "            name =  print_path + '\\\\' + folder_name + '\\\\' + str(i) + '.dat'\n",
    "            data_all[key].cd_df.loc[:, col].to_csv(name, sep = \" \", header=False)\n",
    "            i = i + 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra files if new spectra should be added\n",
    "\n",
    "#excel path\n",
    "print_path = \"F:\\\\HZDR\\\\0_Cloud\\\\ITTFA_PCA\\\\dat\"\n",
    "#excel_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Factor_analysis\\\\ITTFA\"\n",
    "# excel file name\n",
    "excel_name =  excel_path + '\\\\' + 'Cl_4M.xlsx'\n",
    "\n",
    "# open and modify excel \n",
    "df_excel = pd.read_excel(excel_name)\n",
    "df_excel = df_excel.drop(index = 0)\n",
    "df_excel = df_excel.set_index('Wavelength')\n",
    "\n",
    "# create subfiles for spectra\n",
    "for k in df_excel.columns:\n",
    "    name =  print_path + '\\\\' + folder_name + '\\\\' + str(i) + '.dat'\n",
    "    df_excel.loc[:, k].to_csv(name, sep = \" \", header=False)\n",
    "    i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-nursery",
   "metadata": {},
   "source": [
    "### Eigenvector output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"F:\\\\HZDR\\\\0_Cloud\\\\ITTFA_PCA\\\\dat\"\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Control_0M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "for  key in liste:\n",
    "    # create DataFrame for plot\n",
    "    plot_df = pd.DataFrame(index=data_all[key].cd_df.loc[215:300].index)\n",
    "    \n",
    "    # number of components\n",
    "    components = 3\n",
    "    \n",
    "    # read files \n",
    "    for i in range(components):\n",
    "        \n",
    "        name = 'eigenvector' + str(i+1) \n",
    "        # get data path\n",
    "        data_path = os.path.join(print_path, key, name + '.dat')\n",
    "        \n",
    "        # open file and create data list\n",
    "        file = open(data_path, \"r\")\n",
    "        data = []\n",
    "        \n",
    "        # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "        list_of_lines = file.readlines()\n",
    "        for k in range(len(list_of_lines)):\n",
    "            data.extend(re.split(' |\\n', list_of_lines[k]))\n",
    "        data1 = np.array(list(filter(lambda x: x != '', data)))\n",
    "        \n",
    "        # data list reshaped as 2D array and added to plot\n",
    "        data1 = data1.reshape(86, 2)\n",
    "        plot_df[i+1] = data1[:, 1]\n",
    "        \n",
    "    # same procedure for eigenvalues to norm eigenvectors    \n",
    "    name = 'eigenvalues'\n",
    "    data_path = os.path.join(print_path, key, name + '.dat')\n",
    "    # open file and create data list\n",
    "    file = open(data_path, \"r\")\n",
    "    data = []\n",
    "    # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "    list_of_lines = file.readlines()\n",
    "    for k in range(len(list_of_lines)):\n",
    "        data.extend(re.split(' |\\n', list_of_lines[k]))\n",
    "        data1 = np.array(list(filter(lambda x: x != '', data)))\n",
    "    \n",
    "    # data list reshaped as 2D array and added to plot\n",
    "    data1 = data1.reshape(components, 2)\n",
    "    eigenvectors = data1\n",
    "    \n",
    "    # change dtype to float\n",
    "    plot_df = plot_df.astype('float64')\n",
    "    eigenvectors = eigenvectors.astype('float64')\n",
    "    #plot_df = plot_df.multiply(eigenvectors.T[1])\n",
    "    # norm between 0 - 1 if wanted\n",
    "    #plot_df = plot_df.subtract(plot_df.min()).divide((plot_df.max()-plot_df.min()))\n",
    "    plot.mult_func([1,2, 3, 4, 5, 6], [plot_df.T], linestyle=[\"solid\",\"solid\",  'dashed','dashed','dotted', 'dotted'], marker=[\"\",\"\",\"\",\"\",\"\",\"\",\"\"], subtitle=[\"\"], \n",
    "                   x_label=\"wavelength \\ nm\", y_label=\"eigenvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-links",
   "metadata": {},
   "source": [
    "### Varimax Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"F:\\\\HZDR\\\\0_Cloud\\\\ITTFA_PCA\\\\dat\"\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(print_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Control_0M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for  key in liste:\n",
    "    # create DataFrame for plot\n",
    "    plot_df = pd.DataFrame(index=data_all[key].t_list[:-3])\n",
    "    \n",
    "    # number of components\n",
    "    components = 4\n",
    "    \n",
    "    # read files \n",
    "    for i in range(components):\n",
    "        \n",
    "        name = 'VARIMAX_loading_component' + str(i+1) \n",
    "        # get data path\n",
    "        data_path = os.path.join(print_path, key, name + '.dat')\n",
    "        \n",
    "        # open file and create data list\n",
    "        file = open(data_path, \"r\")\n",
    "        data = []\n",
    "        \n",
    "        # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "        list_of_lines = file.readlines()\n",
    "        for k in range(len(list_of_lines)):\n",
    "            data.extend(re.split(' |\\n', list_of_lines[k]))\n",
    "        data = np.array(list(filter(lambda x: x != '', data)))\n",
    "        \n",
    "        # data list reshaped as 2D array and added to plot\n",
    "        data = data.reshape(len(data_all[key].t_list[:-3]), 2)\n",
    "        plot_df[i+1] = data[:, 1]\n",
    "   \n",
    "    # change dtype to float\n",
    "    plot_df = plot_df.astype('float64')\n",
    "    # norm between 0 - 1 if wanted\n",
    "    plot_df = plot_df.subtract(plot_df.min()).divide((plot_df.max()-plot_df.min()))\n",
    "    plot.mult_func([1, 2, 3, 4], [plot_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], marker=[\"o\",\"o\",\"o\",\"o\"], subtitle=[key], \n",
    "                   x_label=\"Temperature [°C]\", y_label=\"Abstract Concentration after Varimax Rotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all[key].t_list, melt_T[key])\n",
    "print(data_all[key].t_list[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-bleeding",
   "metadata": {},
   "source": [
    "### ITTFA Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"F:\\\\HZDR\\\\0_Cloud\\\\ITTFA_PCA\\\\dat\"\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['Control_0M']\n",
    "filename = 'Control_0M'\n",
    "wave_min = 215\n",
    "wave_max = 300 \n",
    "\n",
    "t_min = 20\n",
    "t_max = 90\n",
    "t_list = []\n",
    "\n",
    "for key in key_list:\n",
    "    t_list.extend(data_all[key].cd_df.loc[wave_min:wave_max,t_min:t_max].columns)\n",
    "    # extend for extra spectra\n",
    "    #t_list.insert(0, 10)\n",
    "    #t_list.extend([100, 110,120,130])\n",
    "\n",
    "# create DataFrame for plot\n",
    "conc_df = pd.DataFrame(index=t_list)\n",
    "spec_df = pd.DataFrame(index=data_all[key].cd_df.loc[wave_min:wave_max,t_min:t_max].index)\n",
    "\n",
    "# number of components\n",
    "components = 3\n",
    "    \n",
    "# read files, 1st rel_conectration, 2nd spectra of components and third error in rel concentrations\n",
    "for i in range(components):\n",
    "    name1 = 'rel_concentration_component' + str(i+1) \n",
    "    name2 = 'component' + str(i+1) \n",
    "    \n",
    "    # get data path\n",
    "    data_path1 = os.path.join(print_path, filename, name1 + '.dat')\n",
    "    data_path2 = os.path.join(print_path, filename, name2 + '.dat')\n",
    "        \n",
    "    # open file and create data list\n",
    "    file1 = open(data_path1, \"r\")\n",
    "    file2 = open(data_path2, \"r\")\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "        \n",
    "    # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "    list_of_lines1 = file1.readlines()\n",
    "    list_of_lines2 = file2.readlines()\n",
    "    \n",
    "    for k in range(len(list_of_lines1)):\n",
    "        data1.extend(re.split(' |\\n', list_of_lines1[k]))\n",
    "    data1 = np.array(list(filter(lambda x: x != '', data1)))\n",
    "    \n",
    "    for j in range(len(list_of_lines2)):\n",
    "        data2.extend(re.split(' |\\n', list_of_lines2[j]))\n",
    "    data2 = np.array(list(filter(lambda x: x != '', data2)))\n",
    "    \n",
    "    # data list reshaped as 2D array and added to plot\n",
    "    data1 = data1.reshape(len(t_list), 2)\n",
    "    conc_df[i+1] = data1[:, 1]\n",
    "    \n",
    "    data2 = data2.reshape(len(spec_df.index), 2)\n",
    "    spec_df[i+1] = data2[:, 1]\n",
    "\n",
    "# read relative errors of concentrations\n",
    "name3 = 'error_in_rel_concentrations'\n",
    "data_path3 = os.path.join(print_path, filename, name3 + '.dat')\n",
    "file3 = open(data_path3, \"r\")\n",
    "data3 = []\n",
    "list_of_lines3 = file3.readlines()\n",
    "for j in range(len(list_of_lines3)):\n",
    "    data3.extend(re.split(' |\\n', list_of_lines3[j]))\n",
    "data3 = np.array(list(filter(lambda x: x != '', data3)))\n",
    "data3 = data3.reshape(components, 2)\n",
    "\n",
    "\n",
    "\n",
    "# change dtype to float\n",
    "conc_df = conc_df.astype('float64')\n",
    "spec_df = spec_df.astype('float64')\n",
    "\n",
    "# trying to calculate error\n",
    "data_measured = data_all[key].cd_df.loc[wave_min:wave_max,t_min:t_max]\n",
    "data_calculated = pd.DataFrame(np.matmul(spec_df.to_numpy(), conc_df.to_numpy().T), index=data_measured.index, columns=t_list)\n",
    "\n",
    "# renorm data\n",
    "data_measured = data_measured.divide(data_measured.max(axis=0) - data_measured.min(axis=0))\n",
    "data_calculated  = data_calculated.divide(data_calculated.max(axis=0) - data_calculated.min(axis=0))\n",
    "df_error = np.sqrt(np.square(data_measured.subtract(data_calculated.loc[:,20:90])).sum(axis=0)) / (wave_max - wave_min - 1)\n",
    "#print(df_error.max())\n",
    "# plot.mult_func([20], [data_measured, data_calculated], swap=True)  # plot both together\n",
    "\n",
    "# negative reverse and amplitude adaption\n",
    "#conc_df[2] = conc_df[2] * -1\n",
    "#spec_df[2] = spec_df[2] * -1\n",
    "#conc_df = conc_df * (data_all[key].cd_df.loc[247, 20]/spec_df.loc[247,1])\n",
    "#spec_df = spec_df * (data_all[key].cd_df.loc[247, 20]/spec_df.loc[247,1])\n",
    "# norm between 0 - 1 if wanted\n",
    "#conc_df = conc_df.subtract(conc_df.min()).divide((conc_df.max()-conc_df.min()))\n",
    "\n",
    "plot.mult_func(np.arange(1, components + 1), [conc_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], subtitle=[filename], \n",
    "                x_label=\"temperature / °C\", y_label=\"relative population  / %\", \n",
    "               label=[*np.arange(1, components + 1), \"Melting temperature\"], title=\"Concentration of Components after ITTFA\",\n",
    "               marker=[\"o\", \"X\", \"s\"], \n",
    "               baseline=True, \n",
    "               x_max=75\n",
    "               #vertical_line=[melt_T[filename]]\n",
    "              )    \n",
    "    \n",
    "plot.mult_func(np.arange(1, components + 1), [spec_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], marker=[\"\",\"\",\"\",\"\"], subtitle=[filename], \n",
    "                x_label=\"wavelength / nm\", title=\"Spectra of components from ITTFA\", baseline=True, label=np.arange(1, components + 1),\n",
    "               y_max = [spec_df.T.loc[components].max().max()], y_min = [spec_df.T.loc[components].min().min()], y_scaling=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([1,3,2], [spec_df.T], marker=[\"\",\"\",\"\",\"\"], subtitle=[''], \n",
    "                x_label=\"wavelength /nm\", baseline=True, label=['S1','S2\\'', 'S3'], y_label='abstract ellipticity',\n",
    "              colors=['tab:red', 'tab:grey', 'tab:green'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-warrior",
   "metadata": {},
   "source": [
    "Recalculation and TS-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.matmul(spec_df.to_numpy(), conc_df.to_numpy().T), index=data_measured.index, columns=t_list)\n",
    "max_cd_value = df.abs().max().max()\n",
    "sync,  assync = ana.perturbation_moving_window(df, window_size=3)\n",
    "plot.heatmap(sync, x_min=[215], x_max=[300], x_label='temperature / °C', y_label='wavelength / nm',\n",
    "                 c_label=\"\",c_min=[-1e8], c_max=[1e8], title=\"\", subtitle=[''],\n",
    "                contour_lines=[-0.7*max_cd_value, -0.4*max_cd_value,  -0.2*max_cd_value,  0, 0.2*max_cd_value, \n",
    "                                0.4*max_cd_value, 0.7*max_cd_value],\n",
    "            hline=melt_T[filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data3, df_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all['GdmCl_1M'].t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-fight",
   "metadata": {},
   "source": [
    "*write numbers into excel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "excel_path = print_path + \"\\\\\" + key + \".xlsx\"\n",
    "#with pd.ExcelWriter(excel_path, mode='w') as writer:  \n",
    "    #    data_all[key].absorb_df.to_excel(writer, sheet_name=\"concentration \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(excel_path, mode='w') as writer:  \n",
    "    conc_df.round(6).to_excel(writer, sheet_name=\"concentration \")\n",
    "    \n",
    "with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "    spec_df.round(6).to_excel(writer, sheet_name=\"spectra\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([2, 90], [data_measured.T, data_calculated.T], subtitle=['calculated vs measured spectra of 2nd component'], label=['measured', 'calculated'], x_label='Wavelength / nm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-addiction",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-house",
   "metadata": {},
   "source": [
    "### Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demographic-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste =  [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M', 'GdmCl_6M', 'Gdm2SO4_0.5M','Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M']\n",
    "liste = ['0 M Control', '05 M Gdm2SO4 100 mM Mg', '05 M Gdm2SO4 400 mM Mg', '1 M GdmCl 100 mM Mg', '1 M GdmCl 400 mM Mg', '1 M GdmCl 400 mM Mg 2', '2 M Gdm2SO4 100 mM Mg', '2 M Gdm2SO4 400 mM Mg', '4 M GdmCl', '4 M GdmCl 100 mM Mg', '4 M GdmCl 100 mM Mg 2', '4 M GdmCl 400 mM Mg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "asian-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709d683f15484a1895dde6102dd08aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a993147fd21e4fd68d535f30f1b96dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf81baf47af40488dc0d769de48dbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af977c2260bb4a19a387e203a7c7dc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467b58b8b363412c92a6805b56d3d293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c2f7c23a394bcdb9b43b6515c32238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843eda6d34ec43b18922006404bcf99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1756e7bca3468393610db7ab76b95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e148ed9e9b994eb3ba23cf87866ccc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4682115d1c4c4a45b4b3db9f7489c873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7869cf1b9cb40e2907aa58d6f7653ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c061d79ed9844803b90f00566bc16d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in data_all.keys():\n",
    "    df = data_all[key].cd_df.loc[215:300]\n",
    "    max_cd_value = df.abs().max().max()\n",
    "    plot.heatmap(df, subtitle=[key], title=\"\", x_min=[215], x_max=[300], swap=True,\n",
    "                 x_label=r\"temperature $ / \\ ^{\\circ}C$\", y_label=r\"wavelength $/ \\ nm$\", c_label=r\"molar ellipticity \"\n",
    "                 r\"$ / \\ \\frac{deg \\times cm^{2}}{dmol}$\" , \n",
    "                 contour_lines=[-0.8*max_cd_value, -0.5*max_cd_value,  -0.25*max_cd_value,  0, 0.25*max_cd_value, 0.5*max_cd_value, 0.8*max_cd_value]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all_smooth.keys():\n",
    "    df = data_all_smooth[key].loc[215:300]\n",
    "    max_cd_value = df.abs().max().max()\n",
    "    plot.heatmap(df, subtitle=[key], title=\"\", x_min=[215], x_max=[300], swap=True,\n",
    "                 x_label=r\"temperature $ / \\ ^{\\circ}C$\", y_label=r\"wavelength $/ \\ nm$\", c_label=r\"molar ellipticity \"\n",
    "                 r\"$ / \\ \\frac{deg \\times cm^{2}}{dmol}$\" \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.heatmap(data_all[key].cd_df, subtitle=[\"\"], title=str(key), x_min=[215], swap=True, y_label=\"Temperature [°C]\", x_label=\"Wavelength [nm]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.heatmap(*tuple(data_all.values()), subtitle=tuple(data_all.keys()), title=\"Cd-Values\", x_min=[220]*len(data_all), swap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-techno",
   "metadata": {},
   "source": [
    "### 3D surface plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    df = data_all[key].cd_df.loc[215:310, 1:80]\n",
    "\n",
    "    plot.function3d(df, title=\"\", z_label=r\"molar CD \\ \"\n",
    "                 r\"$ \\frac{deg \\times cm^{2}}{dmol}$\",\n",
    "               x_label='wavelength \\ nm', y_label='temperature \\ °C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-clinton",
   "metadata": {},
   "source": [
    "###  Function Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-slave",
   "metadata": {},
   "source": [
    "#### CD-Spectra Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  data_all[\"0 M Control 10 mM Mg\"].cd_df\n",
    "\n",
    "plot.mult_func([20], [df], swap=True, x_min=215, x_max=300, marker=[''], subtitle=[''], baseline=True, colors=['tab:red'], x_label=\"wavelength / nm\", label=['20 °C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 215\n",
    "wave_max = 330\n",
    "\n",
    "plot.mult_func([230, 247, 275], [data_all['Control_0M'].cd_df.loc[wave_min:wave_max]], \n",
    "               swap=False, x_label=\"Temperature [°C]\", subtitle=[\"\"], \n",
    "               marker=['', '', '', '', '', ''], linestyle=['-', ':', ':', '', '-'], baseline=True, \n",
    "               label=['230','247','275'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 215\n",
    "wave_max = 300\n",
    "\n",
    "key_list = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M' ,'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M',  'GdmCl_4M', 'GdmCl_6M']\n",
    "cd_liste = []\n",
    "for key in key_list:\n",
    "    cd_liste.append(data_all[key].cd_df)\n",
    "    \n",
    "plot.mult_func([20], cd_liste, title=key, swap=True, x_min=wave_min, x_max=wave_max,\n",
    "                   x_label=\"Wavelength [nm]\", y_label=\"CD values [mdeg]\", subtitle=[\"\"],  baseline=True, label=key_list,\n",
    "               marker=[\"\"]*len(key_list)\n",
    "                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = np.zeros(len(key_list))\n",
    "for i in range(len(key_list)):\n",
    "    liste[i] = cd_liste[i].loc[220,20]\n",
    "print(np.mean(liste), np.std(liste), np.mean(liste)/np.std(liste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-joint",
   "metadata": {},
   "source": [
    "#### Max/Min Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-basement",
   "metadata": {},
   "source": [
    "multiple probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniels path:\n",
    "excel_path = \"F:\\\\HZDR\\\\CD_Auswertung\\\\Exel_Max-Min\"\n",
    "# Christophs path:\n",
    "#excel_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\output.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste \n",
    "#liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M',  'GdmCl_0.5M', 'GdmCl_2M', 'GdmCl_2M_24h' , 'GdmCl_4M']\n",
    "liste = ['05 M Gdm2SO4 100 mM Mg', '05 M Gdm2SO4 400 mM Mg', '1 M GdmCl 100 mM Mg', '1 M GdmCl 400 mM Mg', '2 M Gdm2SO4 100 mM Mg', '2 M Gdm2SO4 400 mM Mg', '4 M GdmCl', '4 M GdmCl 100 mM Mg', '4 M GdmCl 100 mM Mg 2', '4 M GdmCl 400 mM Mg']\n",
    "wave_min = 260\n",
    "wave_max =  280\n",
    "\n",
    "for key in data_all.keys():\n",
    "    plot_data =  ana.min_wave(data_all[key].cd_df.abs(), wave_min=wave_min, wave_max=wave_max)\n",
    "    plot_data = plot_data.drop(['Value'], axis=1)   \n",
    "    plot_data.rename(columns = {'Wavelength': key}, inplace = True)\n",
    "    plot.mult_func([key], [plot_data.T], y_scaling=True, y_min=[260], y_max=[265],)\n",
    "    #with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "                    #plot_data.to_excel(writer, sheet_name=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 260\n",
    "wave_max =  280\n",
    "key = \"4 M GdmCl 400 mM Mg\"\n",
    "\n",
    "# First data you want to add to the plot\n",
    "plot_data =  ana.max_wave(data_all[key].cd_df, wave_min=wave_min, wave_max=wave_max)\n",
    "plot_data = plot_data.drop(['Wavelength'], axis=1)   \n",
    "plot_data.rename(columns = {'Value': key}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# other Data you want to add, if always same max/min values then loop would be possible\n",
    "#plot_data[\"GdmCl_4M\"] = ana.max_wave(data_all[\"GdmCl_4M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "#plot_data[\"Gdm2SO4_2M\"] = ana.max_wave(data_all[\"Gdm2SO4_2M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "#plot_data[\"GdmSCN_2M\"] 2= ana.max_wave(data_all[\"GdmSCN_2M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "\n",
    "\n",
    "plot.mult_func([key], [plot_data.T], subtitle=[\"\"], title=\"Max. CD Value between \" + str(wave_min) + ' nm - ' +str(wave_max) + \" nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-istanbul",
   "metadata": {},
   "source": [
    "one probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 260\n",
    "wave_max =  300\n",
    "title = \"Max. CD-Value between \" + str(wave_min) + \"nm - \" + str(wave_max) +\"nm\"\n",
    "\n",
    "for key in data_all.keys():\n",
    "    plot_data =  ana.max_wave(data_all[key].cd_df, wave_min=wave_min, wave_max=wave_max)\n",
    "    plot.mult_func([\"Value\"], [plot_data.T], subtitle=[\"\"],  title=title, label=[key, ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-marina",
   "metadata": {},
   "source": [
    "## Correlation Analyis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-terry",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Noda, I. (2007). Two-dimensional correlation analysis useful for spectroscopy, chromatography, and other analytical measurements. Analytical Sciences, 23(2), 139–146. https://doi.org/10.2116/analsci.23.139\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-telling",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Noda, I. (2015). Techniques of two-dimensional (2D) correlation spectroscopy useful in life science research. Biomedical Spectroscopy and Imaging, 4(2), 109–127. https://doi.org/10.3233/bsi-150105\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-command",
   "metadata": {},
   "source": [
    "### Homogenous Spectrum\n",
    "\n",
    "*optional: pareto scaling, auto scaling and Reference and projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of measurements on which correlation should be performed\n",
    "liste =  ['4 M GdmCl 400 mM Mg']\n",
    "#'Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M'\n",
    "# min and max temperature between which correlations should be analysed\n",
    "t_min = 1\n",
    "t_max = 80\n",
    "\n",
    "for key in liste:\n",
    "    \n",
    "    df =  data_all[key].cd_df.loc[215:300, t_min:t_max]\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[215:300, 20]\n",
    "\n",
    "    sync, assync =  ana.correlation(df, center=True)\n",
    "\n",
    "    plot.heatmap(sync,  title=\"\", c_label= \"\", subtitle=[\"Synchronous Spectrum\"], y_label=\"wavelength / nm\", x_label=\"wavelength / nm\", c_min=[], c_max=[])\n",
    "    plot.heatmap(assync,  title=\"\", c_label= \"\", subtitle=[\"Assynchronous Spectrum\"], y_label=\"wavelength / nm\", x_label=\"wavelength / nm\", c_min=[], c_max=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[\"4 M GdmCl 400 mM Mg\"].cd_df.loc[220:300]\n",
    "\n",
    "\n",
    "# getting index and shared column values\n",
    "idx = df.index\n",
    "col = df.columns\n",
    "\n",
    "# extend measurement points and to create delta_t\n",
    "t_list_extended = np.array(col)\n",
    "t_list_extended = np.insert(t_list_extended, 0, 2 * col[0] - col[1])\n",
    "t_list_extended = np.append(t_list_extended, 2 * col[-1] - col[-2])\n",
    "delta_t = t_list_extended[2:] - t_list_extended[:-2]\n",
    "\n",
    "# from average spectrum\n",
    "dyn = ana.centering(df)\n",
    "\n",
    "# transform to numpy array\n",
    "dyn = dyn.to_numpy()\n",
    "rows, cols = dyn.shape\n",
    "\n",
    "# creating Hilbert-Noda-matrix for async spectrum\n",
    "arr = np.array(col).reshape(1, cols) - np.array(col).reshape(cols, 1) + np.identity(cols)\n",
    "h_n_m = 1 / (2 * np.pi * arr)\n",
    "h_n_m = np.multiply(h_n_m, delta_t)\n",
    "h_n_m = (h_n_m - h_n_m.T) / 2  # change diag to zero\n",
    "\n",
    "# calculate synchronous and asynchronous spectrum with matrix\n",
    "sync_uneven = np.dot(np.multiply(dyn, delta_t), dyn.T) / (2 * (col[-1] - col[0]))\n",
    "\n",
    "assync_uneven = np.zeros((rows, rows))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(rows):\n",
    "                         \n",
    "                         hilbert_transform = np.dot(h_n_m, dyn[j])\n",
    "                         assync_uneven[i,j] = np.sum(np.multiply(dyn[i], hilbert_transform))\n",
    "                    \n",
    "assync_uneven = np.divide(assync_uneven, (2 * (col[-1] - col[0])))\n",
    "        \n",
    "#assync_uneven = np.dot(np.multiply(dyn, delta_t), np.dot(h_n_m, dyn.T)) / (2 * (col[-1] - col[0]))\n",
    "\n",
    "sync_uneven = pd.DataFrame(sync_uneven, index=idx, columns=idx).astype('float64')\n",
    "assync_uneven = pd.DataFrame(assync_uneven, index=idx, columns=idx).astype('float64')\n",
    "\n",
    "df2 = pd.DataFrame(np.dot(h_n_m, dyn.T))\n",
    "df2 = df2.astype('float64')\n",
    "plot.heatmap(sync_uneven,  title=\"\", c_label= \"\", subtitle=[\"Synchronous Spectrum\"], y_label=\"wavelength / nm\", x_label=\"wavelength / nm\" , \n",
    "             c_min=[], c_max=[], contour_lines=[-1.5e7, -0.5e7, 0 , 0.5e7, 1.5e7])\n",
    "plot.heatmap(assync_uneven,  title=\"\", c_label= \"\", subtitle=[\"Assynchronous Spectrum\"], y_label=\"wavelength / nm\", x_label=\"wavelength / nm\", \n",
    "             c_min=[], c_max=[], contour_lines=[-3e5, -1e5, 0, 1e5, 3e5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of measurements on which correlation should be performed\n",
    "#liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M','GdmCl_1M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M']\n",
    "#liste = ['0 M Control 10 mM Mg', '05 M Gdm2SO4 100 mM Mg', '05 M Gdm2SO4 400 mM Mg', '1 M GdmCl 100 mM Mg', '1 M GdmCl 400 mM Mg', '1 M GdmCl 400 mM Mg 2', '2 M Gdm2SO4 100 mM Mg', '2 M Gdm2SO4 400 mM Mg', '4 M GdmCl', '4 M GdmCl 100 mM Mg', '4 M GdmCl 100 mM Mg 2', '4 M GdmCl 400 mM Mg']\n",
    "# min and max temperature between which correlations should be analysed\n",
    "t_min = 20\n",
    "t_max = 90\n",
    "\n",
    "# collection of sync and assync plots\n",
    "sync_dic = {}\n",
    "async_dic ={}\n",
    "\n",
    "# max scaling values for upscaling correlation values with absorption spectrum\n",
    "max_scaling_value_sync = 0\n",
    "max_scaling_value_async = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define witdh of additionaly absorbtion correlation band\n",
    "width = 5\n",
    "\n",
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[215:300, 20]\n",
    "    \n",
    "    # sort out values with HT above 900\n",
    "    df = data_all[key].cd_df.loc[215:300, t_min:t_max]\n",
    "    \n",
    "    # add absorbance as extra row \n",
    "    for i in range(width):\n",
    "        df = df.append(data_all[key].absorb_df.loc[260, t_min:t_max], ignore_index = True)\n",
    "        ref[301+i] = data_all[key].absorb_df.loc[260, 20]\n",
    "    ref.index = np.arange(86 + width)\n",
    "    \n",
    "    # calculate\n",
    "    sync, assync = ana.correlation(df, ref_spec=[ref], center=False)\n",
    "    sync1, assync1 = ana.correlation(data_all[key].cd_df.loc[215:300, t_min:t_max], ref_spec=[data_all[key].cd_df.loc[215:300, 20]], scaling='pareto', center=False)\n",
    "        \n",
    "    # pareto scaling for CD-part\n",
    "    sync.loc[:85, :85] = sync1.to_numpy()\n",
    "    assync.loc[:85, :85] = assync1.to_numpy()\n",
    "    \n",
    "    # get the sacling the absorption values for sync, and assync and compare with max scaling value so far...\n",
    "    max_cd_value_sync = sync.abs().max().max()\n",
    "    max_abs_value_sync = sync.loc[86:].abs().max().max()\n",
    "    max_scaling_value_sync = (max_cd_value_sync / max_abs_value_sync)\n",
    "        \n",
    "    max_cd_value_async = assync.abs().max().max()\n",
    "    max_abs_value_async = assync.loc[86:].abs().max().max()\n",
    "    max_scaling_value_async = (max_cd_value_async / max_abs_value_async)\n",
    "        \n",
    "    print(max_scaling_value_sync, max_scaling_value_async)\n",
    "    # adding DataFrame to plot dics\n",
    "    sync_dic[key] = sync\n",
    "    async_dic[key] =  assync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max scaling values for upscaling correlation values with absorption spectrum\n",
    "max_scaling_value_sync = 21.655153097330512\n",
    "max_scaling_value_async = 19.74706886424258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sync_dic.keys():\n",
    "    max_cd_value = sync_dic[key].abs().max().max()\n",
    "    sync_dic[key].loc[86:] =  sync_dic[key].loc[86:] * max_scaling_value_sync\n",
    "    sync_dic[key].loc[:85,86:] = sync_dic[key].loc[:85,86:] * max_scaling_value_sync\n",
    "    plot.heatmap(sync_dic[key],  title='', subtitle=[\"\" ], y_label=\"Wavelength 1 [nm]\", \n",
    "                 x_label=\"Wavelength 2 [nm]\", c_label=\"\", c_min=[-max_cd_value], c_max=[max_cd_value], hline=85, vline=85,\n",
    "                 contour_lines=[-0.8*max_cd_value,-0.5*max_cd_value, -0.3*max_cd_value, -0.15*max_cd_value, 0, 0.15*max_cd_value, 0.3*max_cd_value, 0.5*max_cd_value, 0.8*max_cd_value])\n",
    "    \n",
    "    max_cd_value = async_dic[key].abs().max().max()\n",
    "    async_dic[key].loc[86:] =  async_dic[key].loc[86:] * max_scaling_value_async\n",
    "    async_dic[key].loc[:85,86:] = async_dic[key].loc[:85,86:] * max_scaling_value_async\n",
    "    plot.heatmap( async_dic[key], title=\"\", subtitle=[ \"\" ], y_label=\"Wavelength 1 [nm]\", \n",
    "                 x_label=\"Wavelength 2 [nm]\",  c_label=\"\", hline=85, vline=85,\n",
    "                 contour_lines=[-0.8*max_cd_value, -0.5*max_cd_value,  -0.3*max_cd_value, -0.15*max_cd_value, 0, 0.15*max_cd_value, 0.3*max_cd_value, \n",
    "                                0.5*max_cd_value, 0.8*max_cd_value] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-spring",
   "metadata": {},
   "source": [
    "### Tools for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-fundamental",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Change 'key' to wanted measurement!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"GdmCl_2M\"\n",
    "key2 = \"GdmCl_2M_24h\"\n",
    "ref1 = data_all[key1].cd_df.loc[:, 20]\n",
    "ref2 = data_all[key2].cd_df.loc[:, 20]\n",
    "sync, assync = ana.correlation(data_all[key1].cd_df.loc[:, :45], data_all[key2].cd_df.loc[:, :45], scaling='pareto', ref_spec=[ref1, ref2], center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(sync, assync,  title=str(key1) + str(key2), subtitle=[\"Synchronous Spectrum\", \"Asynchronous Spectrum\"], x_min=[210, 210], y_min=[210, 210],\n",
    "                y_label= str(key1) + \" WL[nm]\", x_label= str(key2) + \" WL[nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-commissioner",
   "metadata": {},
   "source": [
    "**Diagonal Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sync.to_numpy()\n",
    "diag =  pd.DataFrame(arr.diagonal(), index=sync.index)\n",
    "wave =  list(sync.index)[:-1]\n",
    "diff =  pd.DataFrame(np.diff(arr.diagonal()), index=wave)\n",
    "plot.mult_func([0], [diff.T, diag.T], baseline=True, x_label=\"wavelength [nm]\", subtitle=[\"Diagonal with differential\"], label=[\"CD Values\", \"Differential\"], x_min=210)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-filter",
   "metadata": {},
   "source": [
    "**Line Analyis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength=247\n",
    "# adjust wavelength to shift line analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sync.loc[wavelength, :].to_numpy()\n",
    "df = pd.DataFrame(arr, index=sync.index).T\n",
    "diff = pd.DataFrame(np.diff(arr), index=list(sync.index)[:-1]).T\n",
    "plot.mult_func([0], [df, diff], x_label=\"wavelength [nm]\", baseline=True, x_min=210, subtitle=[\"Synchronous Line Analysis\"], label=[wavelength, \"derivative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-effectiveness",
   "metadata": {},
   "source": [
    "**Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daniels path:\n",
    "excel_path = \"F:\\\\HZDR\\\\CD_Auswertung\\\\2Dcorr\"\n",
    "#Christophs path:\n",
    "#excel_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\output.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-armenia",
   "metadata": {},
   "source": [
    "create new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(excel_path, mode='w') as writer:  \n",
    "\n",
    "                    comp2_conc_df.round(2).to_excel(writer, sheet_name=\"output \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-certificate",
   "metadata": {},
   "source": [
    "Homgeneous Spectra Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste \n",
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M', 'GdmCl_2M_24h' , 'GdmCl_4M', 'GdmCl_6M', 'Urea_2M']\n",
    "t_min = 20\n",
    "t_max = 90\n",
    "\n",
    "\n",
    "\n",
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[:, 20]\n",
    "    # sort out values with HT above 900\n",
    "    df = data_all[key].cd_df\n",
    "    # calculate\n",
    "    sync1, assync1 = ana.correlation(df.loc[:,:45], scaling='pareto', ref_spec=[ref], center=False)\n",
    "    df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "    df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "    with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "                    df1.to_excel(writer, sheet_name=key  + \" sync\")\n",
    "                    df2.to_excel(writer, sheet_name=key  + \" async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-setup",
   "metadata": {},
   "source": [
    "Heterogeneous Spectra Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste\n",
    "\n",
    "#plot_list = [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_2M',  'GdmCl_4M', 'GdmCl_6M']\n",
    "plot_list = [\"Control_0M\", 'Gdm2SO4_0.5M', 'Gdm2SO4_2M',  'Gdm2SO4_4M', 'Gdm2SO4_6M']\n",
    "anzahl = len(plot_list)\n",
    "t_min = 20 \n",
    "t_max = 90\n",
    "\n",
    "\n",
    "# calculation \n",
    "for i in range(anzahl):\n",
    "    for j in range(anzahl):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        df1 = data_all[plot_list[i]].cd_df\n",
    "        df2 = data_all[plot_list[j]].cd_df\n",
    "        ref1 = df1.loc[:, 20]\n",
    "        ref2 = df2.loc[:, 20]\n",
    "        sync1, assync1 = ana.correlation(df1.loc[:, :t_max], df2.loc[:, :t_max], scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "        df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "        df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "        with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "            df1.to_excel(writer, sheet_name=plot_list[i] + \" vs.  \" + plot_list[j]  + \" sync\")\n",
    "            df2.to_excel(writer, sheet_name=plot_list[i] + \" vs.  \" + plot_list[j]  + \" async\")\n",
    "            \n",
    "# extra calculation for 2M vs 2M_24h            \n",
    "\"\"\"df1 = data_all[\"GdmCl_2M\"].cd_df\n",
    "df2 = data_all[\"GdmCl_2M_24h\"].cd_df\n",
    "ref1 = df1.loc[:, 20]\n",
    "ref2 = df2.loc[:, 20]\n",
    "sync1, assync1 = ana.correlation(df1.loc[:, :t_max], df2.loc[:, :t_max], scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "    df1.to_excel(writer, sheet_name=\"2M vs. 2M 24h sync\")\n",
    "    df2.to_excel(writer, sheet_name=\"2M vs. 2M 24h async\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = assync.loc[wavelength, :].to_numpy()\n",
    "df = pd.DataFrame(arr, index=assync.index).T\n",
    "diff = pd.DataFrame(np.diff(arr), index=list(assync.index)[:-1]).T\n",
    "plot.mult_func([0], [df, diff], x_label=\"wavelength [nm]\", baseline=True, x_min=210, subtitle=[\"synchronous Line Analysis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-cookie",
   "metadata": {},
   "source": [
    "### Heterogenous Spectrum\n",
    "\n",
    "*with pareto scaling and Control Measurement as Reference*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_list = [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_2M',  'GdmCl_4M', 'GdmCl_6M']\n",
    "plot_list = [\"Control_0M\", 'Gdm2SO4_0.5M', 'Gdm2SO4_2M',  'Gdm2SO4_4M', 'Gdm2SO4_6M']\n",
    "anzahl = len(plot_list)\n",
    "t_min = 20 \n",
    "t_max = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(anzahl):\n",
    "    for j in range(anzahl):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        title = \"Heterogenoues 2D Correlation between \" + plot_list[i] + \" \" + plot_list[j]\n",
    "        df1 = data_all[plot_list[i]].cd_df\n",
    "        df2 = data_all[plot_list[j]].cd_df\n",
    "        ref1 = df1.loc[:, 20]\n",
    "        ref2 = df2.loc[:, 20]\n",
    "        sync1, assync1 = ana.correlation(df1, df2, scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "        sync2, assync2 = ana.correlation(df1, df2, scaling='auto', ref_spec=[ref1, ref2], center=False)\n",
    "        plot.heatmap(sync1, assync1, title=title, subtitle=[\"Synchronous Spectrum\", \"Asynchronous Spectrum\", \"Synchronous Spectrum\", \"Asynchronous Spectrum\"], x_min=[210, 210, 210, 210], y_min=[210, 210, 210, 210],\n",
    "                y_label= plot_list[i] + \" WL[nm]\", x_label= plot_list[j] + \" WL[nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-syndication",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Perturbation-Correlation Moving-Window 2D Correlation Spectroscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-sarah",
   "metadata": {},
   "source": [
    "*different window size can be choosen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['1_M_GdmCl_100_mM_Mg',  '4_M_GdmCl_100_mM_Mg', '4_M_GdmCl_10_mM_Mg', '4_M_GdmCl_400_mM_Mg']\n",
    "liste = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in liste:\n",
    "    df = data_all[key].cd_df.loc[230:300]\n",
    "    max_cd_value = df.abs().max().max()\n",
    "    sync, assync, = ana.perturbation_moving_window(df, window_size=10)\n",
    "    plot.heatmap(sync, x_min=[230], x_max=[300], \n",
    "                 c_label=\"\", title=\"\", subtitle=[key],\n",
    "                 c_max = [0.5e7], c_min=[-0.5e7],\n",
    "                #contour_lines=[-0.7*max_cd_value, -0.4*max_cd_value,  -0.2*max_cd_value,  0, 0.2*max_cd_value,  0.4*max_cd_value, 0.7*max_cd_value],\n",
    "                hline=melt_T[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-minutes",
   "metadata": {},
   "source": [
    "## Absorbance Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.heatmap(data_all[key].absorb_df, subtitle=[key], title=\"Absorbance Values\", x_min=[215], x_max=[300], c_min=[0]*len(data_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    df = data_all[key].absorb_df\n",
    "    deriv_df = ana.derivative(df)*10\n",
    "    plot.mult_func([260], [df - df.min(axis=1).loc[260], deriv_df], subtitle=[key], linestyle=[\"-\",\":\"], marker=[\"x\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-groove",
   "metadata": {},
   "source": [
    "### Linear LM Fit for Melting Temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-casino",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Determination of melting temperatures and ssDNA fraction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "southeast-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "melt_T = {}\n",
    "comp2_conc = {}\n",
    "#liste = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M', 'GdmCl_6M',  'GdmSCN_0.5M', 'Urea_2M']\n",
    "#liste = ['0 M Control 10 mM Mg', '05 M Gdm2SO4 100 mM Mg', '05 M Gdm2SO4 400 mM Mg', '1 M GdmCl 100 mM Mg', '1 M GdmCl 400 mM Mg', '1 M GdmCl 400 mM Mg 2', '2 M Gdm2SO4 100 mM Mg', '2 M Gdm2SO4 400 mM Mg', '4 M GdmCl', '4 M GdmCl 100 mM Mg', '4 M GdmCl 100 mM Mg 2', '4 M GdmCl 400 mM Mg']\n",
    "liste = ['0 M Control 10 mM Mg']\n",
    "#liste = data_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tamil-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 5\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.9752e-07\n",
      "    reduced chi-square = 9.9174e-08\n",
      "    Akaike info crit   = -79.1860846\n",
      "    Bayesian info crit = -79.9672088\n",
      "[[Variables]]\n",
      "    m:   7.6820e-04 +/- 9.9586e-05 (12.96%) (init = 1)\n",
      "    y0:  0.45460540 +/- 0.00776900 (1.71%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 10\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.5465e-07\n",
      "    reduced chi-square = 3.1831e-08\n",
      "    Akaike info crit   = -170.859561\n",
      "    Bayesian info crit = -170.254391\n",
      "[[Variables]]\n",
      "    m:   1.9850e-04 +/- 1.9643e-05 (9.90%) (init = 1)\n",
      "    y0:  0.38886893 +/- 1.2188e-04 (0.03%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.886\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.9204e-06\n",
      "    reduced chi-square = 2.9204e-06\n",
      "    Akaike info crit   = -37.5271732\n",
      "    Bayesian info crit = -39.3299486\n",
      "[[Variables]]\n",
      "    m:   0.01180000 +/- 0.00120839 (10.24%) (init = 1)\n",
      "    y0: -0.31759567 +/- 0.07855182 (24.73%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a6238b98784369906488ddc9eacdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0 M Control 10 mM Mg': 65.33143041589959}\n",
      "1     0.004186\n",
      "2     0.000689\n",
      "3    -0.000570\n",
      "4    -0.002690\n",
      "5    -0.002077\n",
      "6    -0.003499\n",
      "7     0.000696\n",
      "8     0.000541\n",
      "9    -0.000585\n",
      "10    0.003318\n",
      "11    0.007285\n",
      "12    0.008364\n",
      "13    0.008648\n",
      "14    0.010772\n",
      "15    0.011113\n",
      "16    0.018009\n",
      "17    0.019179\n",
      "18    0.027372\n",
      "19    0.030845\n",
      "20    0.038260\n",
      "21    0.049556\n",
      "22    0.050696\n",
      "23    0.062919\n",
      "24    0.066000\n",
      "25    0.078289\n",
      "26    0.081094\n",
      "27    0.094867\n",
      "28    0.097297\n",
      "29    0.107692\n",
      "30    0.121771\n",
      "31    0.126497\n",
      "32    0.136673\n",
      "33    0.141365\n",
      "34    0.150271\n",
      "35    0.156491\n",
      "36    0.165631\n",
      "37    0.176011\n",
      "38    0.182491\n",
      "39    0.188909\n",
      "40    0.191845\n",
      "41    0.203464\n",
      "42    0.204106\n",
      "43    0.212188\n",
      "44    0.214672\n",
      "45    0.220946\n",
      "46    0.227750\n",
      "47    0.230461\n",
      "48    0.235190\n",
      "49    0.238153\n",
      "50    0.244445\n",
      "51    0.245028\n",
      "52    0.250186\n",
      "53    0.253480\n",
      "54    0.260745\n",
      "55    0.269140\n",
      "56    0.270965\n",
      "57    0.277941\n",
      "58    0.282509\n",
      "59    0.289812\n",
      "60    0.294570\n",
      "61    0.303244\n",
      "62    0.312345\n",
      "63    0.336399\n",
      "64    0.359393\n",
      "65    0.449925\n",
      "66    0.579968\n",
      "67    0.655066\n",
      "68    0.798231\n",
      "69    0.835260\n",
      "70    0.903391\n",
      "71    0.919277\n",
      "72    0.945082\n",
      "73    0.966587\n",
      "74    0.974482\n",
      "75    0.995884\n",
      "76    1.000380\n",
      "77    1.002100\n",
      "78    0.997331\n",
      "79    0.997578\n",
      "80    1.002611\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for key in liste:\n",
    "\n",
    "    # fit three secitons\n",
    "    df =  data_all[key].absorb_df.loc[:,:80]\n",
    "    #high_fit, high_params, high_std =  ana.lm_fit(df.iloc[:,-3:], f_type='linear')\n",
    "    high_fit, high_params, high_std =  ana.lm_fit(df.iloc[:,-5:], f_type='linear')\n",
    "    #low_fit, low_params, low_std =  ana.lm_fit(df.iloc[:,:3], f_type='linear')\n",
    "    low_fit, low_params, low_std =  ana.lm_fit(df.iloc[:,:10], f_type='linear')\n",
    "\n",
    "\n",
    "    # normalize absorbance values and get next 3 values to 0.5\n",
    "    df_norm = ana.normalize(df).loc[260, :]\n",
    "    df_sort = pd.DataFrame(df_norm.iloc[(df_norm-0.5).abs().argsort()[:3]], columns=[260])\n",
    "    # make linear fit\n",
    "    middle_fit, middle_params, middle_std = ana.lm_fit(df.loc[:, df_sort.index], f_type='linear')\n",
    "\n",
    "\n",
    "    # calculate cross of middle and median\n",
    "    melt_T[key] = ( ( (- high_params[\"y0\"] - low_params[\"y0\"]) / 2 ) + middle_params[\"y0\"] ) / ( ( (high_params[\"m\"] + low_params[\"m\"]) / 2 ) - middle_params[\"m\"] ) \n",
    "    # calculate error \n",
    "    teiler = ( ( (high_params[\"m\"] + low_params[\"m\"]) / 2 ) - middle_params[\"m\"] ) \n",
    "    nenner =  ( ( (- high_params[\"y0\"] - low_params[\"y0\"]) / 2 ) + middle_params[\"y0\"] ) \n",
    "    t_melt_error =  np.sqrt( (-0.5 * high_std[\"y0\"] / teiler)**2 + (-0.5 * low_std[\"y0\"] / teiler)**2 + (middle_std[\"y0\"] / teiler)**2\n",
    "                              + (nenner * 0.5 * high_std[\"m\"] / (teiler**2) )**2 + (nenner * 0.5 * low_std[\"m\"] / (teiler**2) )**2 + (nenner * -1 * middle_std[\"m\"] / (teiler**2) )**2)\n",
    "\n",
    "    \n",
    "    # make nice plot\n",
    "    plot_fit= pd.DataFrame(ana.linear(df.columns, *high_params.values()), columns=[\"high plateu\"], index=df.columns)\n",
    "    plot_fit[\"low plateu\"] = ana.linear(df.columns, *low_params.values())\n",
    "    plot_fit[\"middle\"] = ana.linear(df.columns, *middle_params.values())\n",
    "    plot_fit[\"Median\"] = 0.5*(plot_fit[\"high plateu\"] + plot_fit[\"low plateu\"])\n",
    "    #ssDNA\n",
    "    comp2_conc[key] = (df.loc[260] - plot_fit[\"low plateu\"]) / (plot_fit[\"high plateu\"] - plot_fit[\"low plateu\"])\n",
    "\n",
    "    plot.mult_func([260, \"high plateu\", \"low plateu\", \"middle\", \"Median\"], [df, plot_fit.T], \n",
    "                   vertical_line=[melt_T[key]], marker=[\"X\", \"\", \"\", \"\", \"\"], linestyle=[\"--\", \":\", \":\", \"-.\", \"-.\"],\n",
    "                   y_scaling=True, y_min=[df.min(axis=1).loc[260] - 0.02 ], y_max=[df.max(axis=1).loc[260] + 0.02], \n",
    "                   title=\"\", subtitle=[key], sec_ax=[df.min(axis=1).loc[260], df.max(axis=1).loc[260]], y_label=\"absorption / %\",\n",
    "                   x_label='temperature / °C', label=[\"total absorption\",  \"upper baseline\", \"lower baseline\", \"linear interpolation\", \"center line\", \"melting temperature\"])\n",
    "    \n",
    "    print(melt_T)\n",
    "    print(comp2_conc[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(melt_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10, 100, 400]\n",
    "y =  [melt_T['4_M_GdmCl_10_mM_Mg'], melt_T['4_M_GdmCl_100_mM_Mg'], melt_T['4_M_GdmCl_400_mM_Mg']]\n",
    "\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Mg + 4 M GdmCl\"]).T\n",
    "\n",
    "\n",
    "plot.mult_func([\"Mg + 4 M GdmCl\"], [graph1], title=\"\", subtitle=[\"\"], \n",
    "               x_label=\"Mg+ concentration / mM\", y_label=\"temperature / °C\", label=[ r\"$GdmCl$ \"],\n",
    "               marker=[\"X\",\"o\"], linestyle=[\"-.\", \"-\",], backgroundcolor='white', colors=['red',  'black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0., 0.5, 1., 2., 4., 6.]\n",
    "y =  [melt_T[\"Control_0M\"], melt_T[\"Gdm2SO4_0.5M\"], melt_T[\"Gdm2SO4_1M\"], melt_T[\"Gdm2SO4_2M\"], melt_T[\"Gdm2SO4_4M\"], melt_T[\"Gdm2SO4_6M\"]]\n",
    "\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "\n",
    "y2 = [melt_T[\"Control_0M\"], melt_T[\"GdmCl_0.5M\"], melt_T[\"GdmCl_1M\"], melt_T[\"GdmCl_2M\"], melt_T[\"GdmCl_4M\"], melt_T[\"GdmCl_6M\"]]\n",
    "\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], title=\"\", subtitle=[\"\"], \n",
    "               x_label=\"salt concentration / M\", y_label=\"temperature / °C\", label=[r'$Gdm_{2}SO_{4}$',  r\"$GdmCl$ \"],\n",
    "               marker=[\"X\",\"o\"], linestyle=[\"-.\", \"-\",], backgroundcolor='white', colors=['red',  'black'], error={\"Gdm2SO4\": 0.5, \"GdmCl\": 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-gospel",
   "metadata": {},
   "source": [
    "## ITTFA fractions.txt generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-while",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Creates the fractions text files.txt - files which are used for ITTFA.\n",
    "    Melting Temperature must before be determined to calculate ssDNA fraction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to load spectra and to save fraction profiles\n",
    "name = os.path.join(ITTFA_path, 'fractions.txt')\n",
    "key = '0 M Control 10 mM Mg'\n",
    "#ITTFA_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Factor_analysis\\\\ITTFA\"\n",
    "\n",
    "# print key folder to get the name structure \n",
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.path.join(ITTFA_path, 'fractions.txt')\n",
    "key = 'Control_0M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file\n",
    "f = open(name,\"w+\")\n",
    "\n",
    "# extra spectra\n",
    "extra_spectra = 0\n",
    "components = 3\n",
    "\n",
    "# write in file\n",
    "for k in range(components):\n",
    "    for i in range((len(data_all[key].cd_df.loc[:, 20:90].columns) + extra_spectra)):\n",
    "        if k == 1 and i < len(data_all[key].cd_df.loc[:, 20:90].columns):\n",
    "            f.write(\"\\t\" + str(k+1) + \"\\t\" + str(i+1) + \"\\t\" + str(abs(comp2_conc[key].iloc[i].round(2))) + \" \\t 1 \\n\")\n",
    "        elif i >= len(data_all[key].cd_df.loc[:, 20:90].columns) and  k == (i % len(data_all[key].cd_df.loc[:, 20:90].columns)):\n",
    "            f.write(\"\\t\" + str(k+1) + \"\\t\" + str(i+1) + \"\\t\" + str(1) + \"\\t 1 \\n\")\n",
    "        else:\n",
    "            f.write(\"\\t\" + str(k+1) + \"\\t\" + str(i+1) + \"\\t 0 \\t 0 \\n\")\n",
    "\n",
    "# close file\n",
    "f.close()\n",
    "# Bei fehler: \"name 'comp2_conc' is not defined\" den LM Fit laufen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all[key].t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-worth",
   "metadata": {},
   "source": [
    "## Derivative of Absorbtion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "smoking-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f860b4fd551445ca2c1fe70f08ef94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2148a86e2c734d87b49cf9eed8a95bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4679c236b6147f9b0298adaf2170723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2a36edf97941708733ef62c2ea2f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cf81943c92494284580fef91bf56d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bbfec7b0794850a9108fd1bae51f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5951f557e4647e9a50a92033b0b2e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb80a7a83504c848687554ff564f19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad53a33d2d1a4940aba98d5de5db4d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e59cfce06f4e08b596c1762cd96a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c04864cf164ac38d745dace76d05a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4685634e900740ca84c4220c6a9c0515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in data_all.keys():\n",
    "    deriv =  data_all[key].absorb_df.diff(axis = 1) / 0.5\n",
    "    data = data_all[key].absorb_df\n",
    "    plot.mult_func([260], [data], [deriv], title= key, subtitle=[\"Absolute value\", \"interpolated derivative\"], label=[\"\"], y_label=\"Absorbance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "automatic-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f29214d59f74c60b3ba4e118b8d8a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.mult_func([260], [data], [deriv], title= \"Hypochromatic shift\", subtitle=[\"Absolute value\", \"interpolated derivative\"], label=[\"\"], y_label=\"Absorbance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-notion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-abortion",
   "metadata": {},
   "source": [
    "# Calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\Calibration\"\n",
    "datalist = os.listdir(datapath)\n",
    "# 0 for PL, 1 for CSA\n",
    "filename = os.path.join(datapath, datalist[0])\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(filename, \"r\")\n",
    "list_of_lines = file.readlines()\n",
    "\n",
    "# Parameter for head and tail part of document which will be deleted\n",
    "head = 21\n",
    "tail = 1572\n",
    "del list_of_lines[tail:]\n",
    "del list_of_lines[:head]\n",
    "\n",
    "# separating numbers into sublist\n",
    "for i in range(len(list_of_lines)):\n",
    "    list_of_lines[i] = list_of_lines[i].replace(\"\\n\", \"\")\n",
    "    list_of_lines[i] = list_of_lines[i].replace(\",\", \".\")\n",
    "    list_of_lines[i] = list_of_lines[i].split('\\t', 3)\n",
    "\n",
    "# transform list of lists to array of float-type\n",
    "matrix = np.array(list_of_lines)\n",
    "matrix = matrix.astype(np.float)\n",
    "file.close()\n",
    "\n",
    "calibration_data = pd.DataFrame(matrix, columns=['wavelength', 'CD Values', 'HT Values', 'Absorbance'])\n",
    "calibration_data = calibration_data.set_index('wavelength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func(['CD Values'], [calibration_data], swap=True)\n",
    "plot.mult_func(['Absorbance'], [calibration_data], swap=True)\n",
    "plot.mult_func(['HT Values'], [calibration_data], swap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-beach",
   "metadata": {},
   "source": [
    "**Molar Ellipticity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for PL\n",
    "molarity = calibration_data.loc[215,'Absorbance']  * 10**4 / 90 # molarity in mMs\n",
    "print('Determined concentration in mmol/l: \\t', molarity)\n",
    "pathlength =  0.1 # cm \n",
    "print('Ratio experimental vs. theoretical value at the maximum around 290 nm: \\n with determinded molarity: ',\n",
    "      calibration_data.loc[calibration_data['CD Values'].idxmin(axis=0), 'CD Values']  / (0.001* molarity) / (-4.9*3300),\n",
    "      '\\t  with wanted molarity 11.53 mM:' , calibration_data.loc[calibration_data['CD Values'].idxmin(axis=0), 'CD Values']  / (0.001* 11.53) / (-4.9*3300) ) \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CSA\n",
    "molarity = calibration_data.loc[285,'Absorbance'] *  (10**4) / 34.5  # molarity in mMs\n",
    "print('Determined concentration in mmol/l: \\t', molarity)\n",
    "pathlength =  0.1 # cm \n",
    "print('Ratio experimental vs. theoretical value at the maximum around 290 nm: \\n with determinded molarity: ',\n",
    "      calibration_data.loc[calibration_data['CD Values'].idxmax(axis=0), 'CD Values']  / (0.001* molarity) / (7800),  \n",
    "      '\\t  with wanted molarity 4.7 mM:' , calibration_data.loc[calibration_data['CD Values'].idxmax(axis=0), 'CD Values']  / (0.001* 4.7) / (7800)  ) \n",
    "print('Ratio experimental vs. theoretical value at the minimum around 192.5 nm: \\n with determinded molarity: ',\n",
    "      calibration_data.loc[calibration_data['CD Values'].idxmin(axis=0), 'CD Values']  / (0.001* molarity) / (-15600 ),  \n",
    "      '\\t  with wanted molarity 4.7 mM:' , calibration_data.loc[calibration_data['CD Values'].idxmin(axis=0), 'CD Values']  / (0.001* 4.7) / (-15600 ) )\n",
    "print('Ratio between absorbance 285 nm and molar ellipticity at 290.5 nm: ', \n",
    "      (calibration_data.loc[calibration_data['CD Values'].idxmax(axis=0), 'CD Values']  / (3300)) / calibration_data.loc[285, 'Absorbance'],\n",
    "     ' -> this value should be 0.068') # should be 0.068\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-disaster",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-selection",
   "metadata": {},
   "source": [
    "**Zero Crossing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossing = {}\n",
    "\n",
    "wave_max = 280\n",
    "wave_min = 240\n",
    "for key in data_all.keys():\n",
    "    df = data_all[key].cd_df.loc[wave_min:wave_max]\n",
    "    zeros = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        sgn = np.sign(df.loc[wave_min, col])\n",
    "        zero_liste = []\n",
    "        for idx in df.index:\n",
    "            if np.sign(df.loc[idx, col]) != np.sign(sgn):\n",
    "                zero_liste.append(int(idx)+0.5)\n",
    "            sgn = np.sign(df.loc[idx, col])\n",
    "        new = pd.DataFrame({col: zero_liste})\n",
    "        zeros = pd.concat([zeros, new], axis=1)\n",
    "    zero_crossing[key] = zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.mult_func([0], [zero_crossing[key]], subtitle=[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-stuff",
   "metadata": {},
   "source": [
    "**Derivative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_4M - Wiederholung', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_2M_20nM_Origami', 'GdmCl_2M_24h', 'GdmCl_2M_80nM_Origami', 'GdmCl_4M', 'GdmCl_6M', 'GdmCl_6M_70', 'GdmSCN_0.5M', 'GdmSCN_2M', 'GdmSCN_4M', 'Urea_05M', 'Urea_2M']\n",
    "#keys = ['1_M_GdmCl_100_mM_Mg',  '4_M_GdmCl_100_mM_Mg', '4_M_GdmCl_10_mM_Mg', '4_M_GdmCl_400_mM_Mg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    df = data_all[key].cd_df\n",
    "    data = df.to_numpy()\n",
    "    t_vec = df.columns.to_numpy()\n",
    "    delta_x = data[:, 2:] - data[:, :-2]\n",
    "    delta_t = t_vec[2:] - t_vec[:-2]\n",
    "    deriv =  pd.DataFrame(np.divide(delta_x, delta_t), index=df.index, columns=df.iloc[:,1:-1].columns)\n",
    "    deriv = deriv.astype('float64')\n",
    "    plot.heatmap(deriv.loc[215:300], subtitle=[key], title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-postcard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "running-genesis",
   "metadata": {},
   "source": [
    "**Concentration calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "liste = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M','GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M']\n",
    "for key in liste:\n",
    "    df[key] = data_all[key].cd_df[70]\n",
    "    \n",
    "plot.mult_func(liste, [df], swap=True, x_min=215, x_max=300, subtitle=['Data at 70°C'], x_label='Wavelengt / nm' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    absorb_coeff = 0.0263 #ml/µg\n",
    "    conc = data_all[key].absorb_df.loc[260,20] / (absorb_coeff* 0.1) # µg/ml\n",
    "    mol_weight = 4472760.4 *(10**(6)) # µg/mol\n",
    "    conc = conc / mol_weight #mol/ml\n",
    "    conc =  conc * (10**(3)) # mol/L = M\n",
    "    conc = conc * (10**(9)) # nmol/L = nM\n",
    "    \n",
    "    conc2 = data_all[key].absorb_df.loc[260,20] / (0.02* 0.1) # µg/ml\n",
    "    mol_weight = 4472760.4 *(10**(6)) # µg/mol\n",
    "    conc2 = conc2 / mol_weight #mol/ml\n",
    "    conc2 =  conc2 * (10**(3)) # mol/L = M\n",
    "    conc2 = conc2 * (10**(9)) # nmol/L = nM\n",
    "\n",
    "    print(key, round(conc,3), round(conc2, 3), round(conc-conc2,3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daniels path:\n",
    "print_path = \"F:\\\\HZDR\\\\CD_Auswertung\\\\c\"\n",
    "#Chrisophs path\n",
    "#print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Auswertung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = print_path + \"\\\\\" + \"\\\\output.xlsx\"\n",
    "print(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Control_0M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M']\n",
    "for key in liste:\n",
    "    df = data_all[key].absorb_df.loc[260]\n",
    "    with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "        df.round(3).to_excel(writer, sheet_name=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-terrain",
   "metadata": {},
   "source": [
    "**Simulation of Melting Curves**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "serious-exemption",
   "metadata": {},
   "source": [
    "T0\t337\t335,9375\t323,14502\n",
    "dH\t123000\t215000\t100000\n",
    "dS\t364,98516\t640\t309,45858\n",
    "dCp\t2000\t4000\t1000\n",
    "K0\t1\t1,27469\t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gas constant\n",
    "r =  8.314\n",
    "\n",
    "# first process -> melting dsDNA to ssDNA in tensed state\n",
    "t_01 =  337\n",
    "dh_1 = 123000\n",
    "\n",
    "# second process -> melting dsDNA to ssDNA in relaxed state\n",
    "t_02 = 335.9375\n",
    "dh_2 = 215000\n",
    "\n",
    "# third process -> relaxing origami in dsDNA\n",
    "t_03 = 323.14502\n",
    "dh_3 = 10000 \n",
    "\n",
    "# add dc_p values\n",
    "dc_1 = 2000\n",
    "dc_2 = 4000\n",
    "dc_3 = 1000\n",
    "\n",
    "# temperature points and dt to reference temperature t_01\n",
    "t =  np.arange(273, 372, 1)\n",
    "\n",
    "# create lists to save calcua\n",
    "rel_conc = pd.DataFrame(index=t, columns=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractions for all temperature points\n",
    "for i in t:\n",
    "    # calculate dg\n",
    "    dg_1 = - (dh_1/t_01 - dc_1) * (i - t_01) + dc_1 * i * np.log(t_01/i) # dsDNA to ssDNA in tensed state \n",
    "    dg_2 = - (dh_2/t_01 - dc_2) * (i - t_02) + dc_2 * i * np.log(t_02/i) # dsDNA to ssDNA in relaxed state\n",
    "    dg_3 = - (dh_3/t_01 - dc_3) * (i - t_03) + dc_3 * i * np.log(t_03/i) # tensed state to relaxed state in dsDNA\n",
    "    \n",
    "    # calculate equilibrium constants k\n",
    "    k_1 = np.exp( - dg_1 / (r * i))\n",
    "    k_2 = np.exp( - dg_2 / (r * i))\n",
    "    k_3 = np.exp( - dg_3 / (r * i))\n",
    "    \n",
    "    # calculate relative concentrations\n",
    "    sum_of_states = 1 + k_1 + k_3 + k_3 * k_2 # number of states / number of state 1 \n",
    "    rel_conc.loc[i, 1] = 1 / sum_of_states # norm.population of dsDNA tensed \n",
    "    rel_conc.loc[i, 2] = k_1 /sum_of_states # norm.population of ssDNA tensed\n",
    "    rel_conc.loc[i, 3] = k_3 /sum_of_states # norm.population of dsDNA relaxed\n",
    "    rel_conc.loc[i, 4] = k_3 * k_2 /sum_of_states # norm.population of ssDNA relaxed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([1,2,3,4], [rel_conc.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-harvard",
   "metadata": {},
   "source": [
    "**Beers Law**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    absorbance = data_all[key].absorb_df.loc[260, 20]\n",
    "    df = data_all[key].cd_df\n",
    "    \n",
    "    #conc_ds =  absorbance/(0.02*0.1) #[µg/mL]\n",
    "    conc_ds =  absorbance/(0.0263*0.1) #[µg/mL] ecact for gc content in origami triangles\n",
    "    molar = conc_ds * 10**(-6) / (4472760.4 * 10**(-3)) * (10**9) #[nmol/l] \n",
    "    df_norm = 100 * df / (molar * 0.1)    \n",
    "    print(key, \":  \\t\", molar , 'nM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.mult_func([280], [data_all[key].cd_df], subtitle=[key], y_scaling=False, y_max=[], y_min=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # put second y_axis for \"GdmCl_0.5M\" normed\n",
    "        # function to bring back values\n",
    "        def expand_back(y):\n",
    "            return y * (0.523893 - 0.379531) + 0.379531\n",
    "        # inverse function\n",
    "        def norm(y):\n",
    "            return (y - 0.379531) / (0.523893 - 0.379531)\n",
    "\n",
    "        # put axis and label\n",
    "        secax = ax.secondary_yaxis('right', functions=(expand_back, norm), fontsize=16)\n",
    "        secax.set_ylabel('Absorption [%]', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[\"Control_0M\"].cd_df\n",
    "mean = df.mean(axis=1)\n",
    "var =  df.var(axis=1)\n",
    "dyn = df.subtract(mean, axis=0)\n",
    "\n",
    "col = dyn.columns \n",
    "idx = dyn.index\n",
    "m = len(col)\n",
    "n =len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1 =  247\n",
    "wave2 = 260\n",
    "i = 20\n",
    "\n",
    "print(np.sum((dyn.loc[wave1, :]/mean[wave1] - dyn.loc[wave2, :]/mean[wave2]) * col) * np.sqrt(var.loc[wave1]*var.loc[wave2])/(m*(m-1)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assync = pd.DataFrame(np.zeros((n,n)), index=idx, columns=idx)\n",
    "\n",
    "for j in idx:\n",
    "    for k in idx:\n",
    "        assync.loc[j,k] = np.sum((dyn.loc[j, :]/mean[j] - dyn.loc[k, :]/mean[k]) * col) * np.sqrt(var.loc[j]*var.loc[k])/(m*(m-1))\n",
    "print(assync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(assync, x_min=[220], y_min=[220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-rebel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-arthritis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read by default 1st sheet of an excel file\n",
    "print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Auswertung\\\\\"\n",
    "data_path1 = os.path.join(print_path, 'AveragedSpectra.xlsx')\n",
    "df= pd.read_excel(data_path1)\n",
    "df= df.drop(0, axis=0)\n",
    "df = df.set_index('Wavelength')\n",
    "plot.mult_func(['S1', 'S2', 'S2\\'', 'S3'], [df.T], marker=['','','',''], subtitle=[''], x_label='wavelength / nm',\n",
    "              colors=['tab:red', 'tab:blue', 'tab:grey', 'tab:green'], y_label='relative ellipticity', baseline=True, backgroundcolor='#FAFFCD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-kernel",
   "metadata": {},
   "source": [
    "# MD H-bonds Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"C:\\\\Users\\\\crazy\\\\Documents\\\\Uni\\\\Masterarbeit\\\\Thesis\\\\MD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Hbonds-Gdm2SO4-DNA_to_Gdm.dat', 'Hbonds-Gdm2SO4-DNA_to_wat.dat','Hbonds-Gdm2SO4-withinDNA.dat',\n",
    "         'Hbonds-GdmCl-DNA_to_Gdm.dat', 'Hbonds-GdmCl-DNA_to_wat.dat', 'Hbonds-GdmCl-withinDNA.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in liste:\n",
    "\n",
    "    \n",
    "    # get data path\n",
    "    data_path = os.path.join(print_path, name)\n",
    "  \n",
    "    # open file and create data list\n",
    "    file = open(data_path, \"r\")\n",
    "    data = []\n",
    "        \n",
    "    # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "    list_of_lines = file.readlines()\n",
    "    \n",
    "    \n",
    "    for k in range(len(list_of_lines)):\n",
    "        data.extend(re.split(' |\\n', list_of_lines[k]))\n",
    "        data1 = np.array(list(filter(lambda x: x != '', data)))\n",
    "    \n",
    "  \n",
    "    # data list reshaped as 2D array and added to plot\n",
    "    data1 = data1.reshape(len(list_of_lines), 2)\n",
    "\n",
    "    df =  pd.DataFrame(data1, columns=['frame', 'Hbonds'])\n",
    "    df = df.set_index('frame')\n",
    "    df = df.astype('int')\n",
    "    print(name, ': \\ ', df['Hbonds'].mean(), '+-', df['Hbonds'].std())\n",
    "    \n",
    "    #array = np.array(df['Hbonds'].min(), df['Hbonds'].max()+1, 2)\n",
    "    \n",
    "    # setup the plot\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    \n",
    "    df.hist(column='Hbonds', bins=np.arange(50, 101, 2), grid=False, histtype='stepfilled', ax=ax)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('number of h-bonds')\n",
    "    ax.set_ylabel('number of frames')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-huntington",
   "metadata": {},
   "source": [
    "# Parafak Ethanol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-onion",
   "metadata": {},
   "source": [
    "## *setting up the Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-allen",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (11,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-plaza",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Daniel:\n",
    "path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "\n",
    "# My Path:\n",
    "#path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\Ethanol\"\n",
    "datalist = os.listdir(path)\n",
    "print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_all = {}\n",
    "for i in range(len(datalist)):\n",
    "    data_all[datalist[i]] = cdata.CData(os.path.join(path, datalist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  data_all[\"Control_0%\"].cd_df\n",
    "df = df.rename(columns={-1:\"0%\"})\n",
    "df[\"50%\"] =  (data_all[\"Ethanol_50%\"].cd_df.loc[:,-1])\n",
    "df[\"nach\"] =  (data_all[\"Ethanol_50%_nachTest\"].cd_df.loc[:,-1])\n",
    "df[\"vor\"] =  (data_all[\"Ethanol_50%_vorTest\"].cd_df.loc[:,-1])\n",
    "df[\"50% real\"] =  (data_all[\"Ethanol_50%_real\"].cd_df.loc[:,-1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func(['0%', 'vor', 'nach', '50%', \"50% real\" ], [df], swap=True, marker=[\"\", \"\", \"\", \"\", \"\"], x_label=\"Wavelengt [nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-community",
   "metadata": {},
   "source": [
    "# Salmon testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-facing",
   "metadata": {},
   "source": [
    "## setting up the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "import openpyxl\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-incentive",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-battlefield",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Daniel:\n",
    "#path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "\n",
    "# My Path:\n",
    "path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\Salmon Testes\"\n",
    "datalist_salmon = os.listdir(path)\n",
    "print(datalist_salmon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_salmon = {}\n",
    "for i in range(len(datalist_salmon)):\n",
    "    data_salmon[datalist_salmon[i]] = cdata.CData(os.path.join(path, datalist_salmon[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_salmon.keys():\n",
    "    absorbance = data_salmon[key].absorb_df.loc[260, 20]\n",
    "    df = data_salmon[key].cd_df\n",
    "    \n",
    "    conc_ds =  absorbance/(0.02*0.1*(10**3)) #[mg/mL]\n",
    "    print(key, \":  \\t\", conc_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_salmon.keys():\n",
    "    plot.mult_func([260], [data_salmon[key].absorb_df], subtitle=[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_salmon[\"Control_0M_continous\"].t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([20, 40, 60, 80], [data_salmon['Control_0M_continous'].cd_df], swap=True, baseline=True, marker=[\"\",\"\",\"\",\"\"], subtitle=[\"Salmon Control\"], linestyle=[\"-\",\":\", \":\", \"-\"], x_min=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-relaxation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-shark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
