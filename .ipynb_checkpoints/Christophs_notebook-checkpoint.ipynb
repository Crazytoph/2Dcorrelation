{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-cursor",
   "metadata": {},
   "source": [
    "*for more information, checkout* [Github](https://github.com/Crazytoph/2Dcorrelation \"my github page\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-argentina",
   "metadata": {},
   "source": [
    "**CD Measurements - Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-beauty",
   "metadata": {},
   "source": [
    "# DNA Origami "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-setting",
   "metadata": {},
   "source": [
    "## *setting up the Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intermediate-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "import openpyxl\n",
    "import re\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forbidden-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-insured",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selective-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modern-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# activate Latex, change font type\\nplt.rcParams.update({\\n    \"text.usetex\": True,\\n    \"font.family\": \"sans-serif\",\\n    \"font.serif\": [\"Helvetica\"],\\n})'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "\"\"\"# activate Latex, change font type\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.serif\": [\"Helvetica\"],\n",
    "})\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-belfast",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brown-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['46_forward', '46_reversed', 'Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_2M_24h', 'GdmCl_4M', 'GdmCl_6M', 'GdmCl_6M_alt', 'GdmSCN_0.5M', 'GdmSCN_2M', 'Urea_2M']\n"
     ]
    }
   ],
   "source": [
    "# Path for Daniel:\n",
    "#path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "\n",
    "# My Path:\n",
    "path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\DNA Origami\"\n",
    "datalist = os.listdir(path)\n",
    "print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "danish-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_all = {}\n",
    "for i in range(len(datalist)):\n",
    "    data_all[datalist[i]] = cdata.CData(os.path.join(path, datalist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endangered-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cdata.CData object at 0x000001A3F9177130>\n",
      "[<cdata.CData object at 0x000001A3F9177130>, <cdata.CData object at 0x000001A3FE3EBD90>]\n",
      "(<cdata.CData object at 0x000001A3F9189BE0>, <cdata.CData object at 0x000001A3F91770D0>, <cdata.CData object at 0x000001A3F9177130>, <cdata.CData object at 0x000001A3FE332A30>)\n"
     ]
    }
   ],
   "source": [
    "# options to acces data\n",
    "print(data_all['Control_0M'])\n",
    "# multiple options\n",
    "print(list(map(data_all.get, ['Control_0M', 'Gdm2SO4_4M'])))\n",
    "print(tuple(data_all.values())[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-particle",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-edgar",
   "metadata": {},
   "source": [
    "### Print-out for PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indirect-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moving-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [ 'GdmCl_0.5M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "psychological-edwards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i= 1\n",
    "\n",
    "for key in liste:\n",
    "    for col in data_all[key].cd_df.columns:\n",
    "        name =  print_path + '\\\\' + 'GdmCl_0.5M' + '\\\\' + str(i) + '.dat'\n",
    "        data_all[key].cd_df.loc[:, col].to_csv(name, sep = \" \", header=False)\n",
    "        i = i + 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all[\"Control_0M\"].t_list,\"\\n\", data_all[\"GdmCl_0.5M\"].t_list, \"\\n\", data_all[\"GdmCl_2M\"].t_list, \"\\n\", data_all[\"GdmCl_4M\"].t_list, \"\\n\", data_all[\"GdmCl_6M\"].t_list, \"\\n\", melt_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-electronics",
   "metadata": {},
   "source": [
    "### einlesen von Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "matched-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(print_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-address",
   "metadata": {},
   "source": [
    "*VARIMAX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "resistant-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Gdm2SO4_1M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mediterranean-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211dfbe9ff3c4f3a9597fcdd6e48d6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for  key in liste:\n",
    "    # create DataFrame for plot\n",
    "    plot_df = pd.DataFrame(index=data_all[key].t_list)\n",
    "    \n",
    "    # number of components\n",
    "    components = 3\n",
    "    \n",
    "    # read files \n",
    "    for i in range(components):\n",
    "        \n",
    "        name = 'VARIMAX_loading_component' + str(i+1) \n",
    "        # get data path\n",
    "        data_path = os.path.join(print_path, key, name + '.dat')\n",
    "        \n",
    "        # open file and create data list\n",
    "        file = open(data_path, \"r\")\n",
    "        data = []\n",
    "        \n",
    "        # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "        list_of_lines = file.readlines()\n",
    "        for k in range(len(list_of_lines)):\n",
    "            data.extend(re.split(' |\\n', list_of_lines[k]))\n",
    "        data = np.array(list(filter(lambda x: x != '', data)))\n",
    "        \n",
    "        # data list reshaped as 2D array and added to plot\n",
    "        data = data.reshape(len(data_all[key].t_list), 2)\n",
    "        plot_df[i+1] = data[:, 1]\n",
    "   \n",
    "    # change dtype to float\n",
    "    plot_df = plot_df.astype('float64')\n",
    "    # norm between 0 - 1 if wanted\n",
    "    plot_df = plot_df.subtract(plot_df.min()).divide((plot_df.max()-plot_df.min()))\n",
    "    plot.mult_func([1, 2, 3], [plot_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], marker=[\"o\",\"o\",\"o\",\"o\"], subtitle=[key], \n",
    "                   x_label=\"Temperature [°C]\", y_label=\"Abstract Concentration after Varimax Rotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "classified-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 20, 30, 40, 45, 50, 53, 56, 58, 60, 62, 64, 67, 70, 75, 80, 90] 65.7219345117269\n",
      "[20, 30, 40, 45, 50, 53, 56, 58, 60, 62, 64, 67, 70, 75, 80, 90]\n"
     ]
    }
   ],
   "source": [
    "print(data_all[key].t_list, melt_T[key])\n",
    "print(data_all[key].t_list[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "magnetic-modern",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6309546f9033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcd_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m247\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mspec_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m247\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    829\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3738\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3740\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "print(data_all[key].cd_df.loc[247, 20]/spec_df.loc[247,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "integral-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af953b2129f434a8bf68296fde705b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36501b068d164ebeaa0149426a06d273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = \"Gdm2SO4_0.5M\"\n",
    "wave_min = 215\n",
    "wave_max = 300 \n",
    "\n",
    "t_list =  data_all[key].t_list\n",
    "\n",
    "# create DataFrame for plot\n",
    "conc_df = pd.DataFrame(index=t_list)\n",
    "spec_df = pd.DataFrame(index=data_all[key].cd_df.loc[wave_min:wave_max,20:].index)\n",
    "# number of components\n",
    "components = 4\n",
    "    \n",
    "# read files \n",
    "for i in range(components):\n",
    "    name1 = 'rel_concentration_component' + str(i+1) \n",
    "    name2 = 'component' + str(i+1) \n",
    "    # get data path\n",
    "    data_path1 = os.path.join(print_path, key, name1 + '.dat')\n",
    "    data_path2 = os.path.join(print_path, key, name2 + '.dat')\n",
    "        \n",
    "    # open file and create data list\n",
    "    file1 = open(data_path1, \"r\")\n",
    "    file2 = open(data_path2, \"r\")\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "        \n",
    "    # list of lines, of which all elemnts equal to space or enter are used as split, and then empty elements are deleted\n",
    "    list_of_lines1 = file1.readlines()\n",
    "    list_of_lines2 = file2.readlines()\n",
    "    \n",
    "    for k in range(len(list_of_lines1)):\n",
    "        data1.extend(re.split(' |\\n', list_of_lines1[k]))\n",
    "    data1 = np.array(list(filter(lambda x: x != '', data1)))\n",
    "    \n",
    "    for j in range(len(list_of_lines2)):\n",
    "        data2.extend(re.split(' |\\n', list_of_lines2[j]))\n",
    "    data2 = np.array(list(filter(lambda x: x != '', data2)))\n",
    "    \n",
    "\n",
    "    # data list reshaped as 2D array and added to plot\n",
    "    data1 = data1.reshape(len(t_list), 2)\n",
    "    conc_df[i+1] = data1[:, 1]\n",
    "    \n",
    "    data2 = data2.reshape(len(data_all[key].cd_df.loc[wave_min:wave_max, 20].index), 2)\n",
    "    spec_df[i+1] = data2[:, 1]\n",
    "   \n",
    "# change dtype to float\n",
    "conc_df = conc_df.astype('float64')\n",
    "spec_df = spec_df.astype('float64')\n",
    "\n",
    "# negative reverse and amplitude adaption\n",
    "#conc_df[2] = conc_df[2] * -1\n",
    "#spec_df[2] = spec_df[2] * -1\n",
    "#conc_df = conc_df * (data_all[key].cd_df.loc[247, 20]/spec_df.loc[247,1])\n",
    "#spec_df = spec_df * (data_all[key].cd_df.loc[247, 20]/spec_df.loc[247,1])\n",
    "# norm between 0 - 1 if wanted\n",
    "#conc_df = conc_df.subtract(conc_df.min()).divide((conc_df.max()-conc_df.min()))\n",
    "\n",
    "plot.mult_func([1, 2, 3, 4], [conc_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], subtitle=[key], \n",
    "                x_label=\"Temperature [°C]\", y_label=\"Relative Concentration [ %]\", vertical_line=[melt_T[key]], \n",
    "               label=[\"Component 1\", \"Component 2\", \"Component 3\", \"Component 4\", \"Melting Temperature\"], title=\"Concentration of Components after ITTFA\",\n",
    "               marker=[\"o\", \"X\", \"s\"],\n",
    "              )    \n",
    "    \n",
    "plot.mult_func([1, 2, 3, 4], [spec_df.T], linestyle=[\"solid\",\"dashdot\",\"dashed\",\"dotted\"], marker=[\"\",\"\",\"\",\"\"], subtitle=[key], \n",
    "                x_label=\"Wavelength [nm]\", title=\"Spectra of Components from ITT\", baseline=True, label=[\"Component 1\", \"Component 2\", \"Component 3\", \"Component 4\"],\n",
    "               y_max = [spec_df.T.loc[4].max().max()], y_min = [spec_df.T.loc[4].min().min()], y_scaling=False )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "completed-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.66942154950801\n"
     ]
    }
   ],
   "source": [
    "print(spec_df.T.loc[1].max().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-variation",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-permission",
   "metadata": {},
   "source": [
    "### Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forbidden-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste =  [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M', 'GdmCl_6M', 'Gdm2SO4_0.5M','Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collective-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c6e18aebd543cf89d7870d8957f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.88046407740443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50c69b01c9a494e9cce720b427ff232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.87554508796475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6608d841845049bf992da0e8a19bcaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.7219345117269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f660ba4713447b9b2cc0afedadb9f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.22456104786192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0222008dbae84c97bb218072107caa0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.194612694153875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e345bf256543c9a129cee5cc66b234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.41120314608025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0668763b27f647ecbda77861979e2d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.52277673479793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668f8615884c410c8a6f6092022d7119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.84295918577699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd7498be18f41d6a61366196d8dac4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.33702771140105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea59895c931540a58563a03e0f3e5a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.39728202507145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafe4efe5af34904ad9c11594ca36002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.39443444391862\n"
     ]
    }
   ],
   "source": [
    "for key in liste:\n",
    "    df = data_all[key].cd_df.loc[215:300,20:]\n",
    "    max_cd_value = df.abs().max().max()\n",
    "    plot.heatmap(df, subtitle=[key], title=\"\", x_min=[215], x_max=[300], swap=True,\n",
    "                 x_label=r\"Temperature $[^{\\circ}C]$\", y_label=r\"Wavelength $[nm]$\", c_label=r\"CD- Values \"\n",
    "                 r\"$[\\frac{deg \\times cm^{2}}{dmol}]$\", hline=melt_T[key], backgroundcolor='#FDEADA', \n",
    "                 contour_lines=[-0.8*max_cd_value, -0.5*max_cd_value,  -0.25*max_cd_value,  0, 0.25*max_cd_value, \n",
    "                                0.5*max_cd_value, 0.8*max_cd_value]\n",
    "                )\n",
    "    print(melt_T[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.heatmap(data_all[key].cd_df, subtitle=[\"\"], title=str(key), x_min=[215], swap=True, y_label=\"Temperature [°C]\", x_label=\"Wavelength [nm]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.heatmap(*tuple(data_all.values()), subtitle=tuple(data_all.keys()), title=\"Cd-Values\", x_min=[220]*len(data_all), swap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-monkey",
   "metadata": {},
   "source": [
    "### 3D surface plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[\"Control_0M\"].cd_df.loc[215:300]\n",
    "\n",
    "plot.function3d(df, title=\"\", backgroundcolor='#FDEADA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-grenada",
   "metadata": {},
   "source": [
    "###  Function Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-greene",
   "metadata": {},
   "source": [
    "#### CD-Spectra Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  data_all[\"Control_0M\"].absorb_df\n",
    "\n",
    "plot.mult_func([260], [df], swap=False, \n",
    "               x_label=\"temperature / °C\", subtitle=[r\"Control\"], y_label=r\"absorbance / % \", \n",
    "               vertical_line=[melt_T['Control_0M']], marker=[\"x\"], linestyle=[\":\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 215\n",
    "wave_max = 300\n",
    "\n",
    "key_list = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', \"Gdm2SO4_6M\"]\n",
    "plot.mult_func([50], [data_all[\"Control_0M\"].cd_df.loc[wave_min:wave_max], data_all[\"Gdm2SO4_0.5M\"].cd_df.loc[wave_min:wave_max],\n",
    "                                  data_all[\"Gdm2SO4_2M\"].cd_df.loc[wave_min:wave_max], data_all[\"Gdm2SO4_4M\"].cd_df.loc[wave_min:wave_max], \n",
    "                                  data_all[\"Gdm2SO4_6M\"].cd_df.loc[wave_min:wave_max]], \n",
    "               swap=True, x_label=\"Wavelength [nm]\", subtitle=[\"\"], \n",
    "               marker=['', '', '', '', '', ''], linestyle=['-', ':', ':', '', '-'], baseline=True, \n",
    "               label=[\"0M\",\"0.5M\", \"2M\", \"4M\", \"6M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 200\n",
    "wave_max = 330\n",
    "\n",
    "key_list = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'GdmCl_0.5M', 'GdmCl_2M',  'GdmCl_4M', 'GdmSCN_0.5M', 'GdmSCN_2M']\n",
    "for key in key_list:\n",
    "    plot.mult_func([20, 45, 64, 80], [data_all[key].cd_df.loc[wave_min:wave_max]], title=key, swap=True,\n",
    "                   x_label=\"Wavelength [nm]\", y_label=\"CD values [mdeg]\", subtitle=[\"\"], label=[\"20°C\", \"45°C\", \"64°C\", \"80°C\"], marker=['', '', '', ''], linestyle=['-', ':', ':', '-'], baseline=True, \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for key in data_all.keys():\n",
    "    data.append([data_all[key].cd_df.T])\n",
    "\n",
    "plot.mult_func([20, 40, 55, 60, 65, 70, 90], *data, subtitle=tuple(data_all.keys()),\n",
    "               title=\"CD-Spectra\", marker=[\"\",\"\", \"\", \"\", \"\", \"\", \"\"], x_min=210\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-longer",
   "metadata": {},
   "source": [
    "#### Max/Min Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-accuracy",
   "metadata": {},
   "source": [
    "multiple probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\output.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "stopped-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste \n",
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M',  'GdmCl_0.5M', 'GdmCl_2M', 'GdmCl_2M_24h' , 'GdmCl_4M']\n",
    "wave_min = 260\n",
    "wave_max =  280\n",
    "\n",
    "for key in liste:\n",
    "    plot_data =  ana.min_wave(data_all[key].cd_df.abs(), wave_min=wave_min, wave_max=wave_max)\n",
    "    plot_data = plot_data.drop(['Value'], axis=1)   \n",
    "    plot_data.rename(columns = {'Wavelength': key}, inplace = True)\n",
    "    with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "                    plot_data.to_excel(writer, sheet_name=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "inside-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d949240e44942669d5df8952a8bd7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wave_min = 260\n",
    "wave_max =  280\n",
    "key = \"Gdm2SO4_0.5M\"\n",
    "\n",
    "# First data you want to add to the plot\n",
    "plot_data =  ana.max_wave(data_all[key].cd_df, wave_min=wave_min, wave_max=wave_max)\n",
    "plot_data = plot_data.drop(['Wavelength'], axis=1)   \n",
    "plot_data.rename(columns = {'Value': key}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# other Data you want to add, if always same max/min values then loop would be possible\n",
    "#plot_data[\"GdmCl_4M\"] = ana.max_wave(data_all[\"GdmCl_4M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "#plot_data[\"Gdm2SO4_2M\"] = ana.max_wave(data_all[\"Gdm2SO4_2M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "#plot_data[\"GdmSCN_2M\"] 2= ana.max_wave(data_all[\"GdmSCN_2M\"].cd_df, wave_min=wave_min, wave_max=wave_max)[\"Value\"]\n",
    "\n",
    "\n",
    "plot.mult_func([key], [plot_data.T], subtitle=[\"\"], title=\"Max. CD Value between \" + str(wave_min) + 'nm - ' +str(wave_max) + \" nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-adoption",
   "metadata": {},
   "source": [
    "one probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 260\n",
    "wave_max =  290\n",
    "title = \"Max. CD-Value between \" + str(wave_min) + \"nm - \" + str(wave_max) +\"nm\"\n",
    "\n",
    "for key in data_all.keys():\n",
    "    plot_data =  ana.max_wave(data_all[key].cd_df, wave_min=wave_min, wave_max=wave_max)\n",
    "    plot.mult_func([\"Value\"], [plot_data.T], subtitle=[\"\"], vertical_line=[melt_T[key]], title=title, label=[key, \"melting Temp.\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-xerox",
   "metadata": {},
   "source": [
    "## Correlation Analyis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-scoop",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Noda, I. (2007). Two-dimensional correlation analysis useful for spectroscopy, chromatography, and other analytical measurements. Analytical Sciences, 23(2), 139–146. https://doi.org/10.2116/analsci.23.139\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-chorus",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Noda, I. (2015). Techniques of two-dimensional (2D) correlation spectroscopy useful in life science research. Biomedical Spectroscopy and Imaging, 4(2), 109–127. https://doi.org/10.3233/bsi-150105\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-ukraine",
   "metadata": {},
   "source": [
    "### Homogenous Spectrum\n",
    "\n",
    "*optional: pareto scaling, auto scaling and Reference and projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of measurements on which correlation should be performed\n",
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M','GdmCl_1M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M']\n",
    "#'Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M'\n",
    "# min and max temperature between which correlations should be analysed\n",
    "t_min = 20\n",
    "t_max = 90\n",
    "\n",
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[215:300, 20]\n",
    "    \n",
    "    # sort out values with HT above 900\n",
    "    df = data_all[key].cd_df.loc[215:300, :t_max]\n",
    "    \n",
    "    sync, assync =  ana.correlation(df, ref_spec=[ref], scaling='auto',  center=False)\n",
    "    for i in df.index:\n",
    "        for j in df.index:\n",
    "            if sync.loc[i,j] == 0:\n",
    "                sync.loc[i, j] = 1\n",
    "    plot_df = assync.divide(sync)\n",
    "\n",
    "    plot.heatmap(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of measurements on which correlation should be performed\n",
    "liste =  liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M','GdmCl_1M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M']\n",
    "#'Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M'\n",
    "# min and max temperature between which correlations should be analysed\n",
    "t_min = 20\n",
    "t_max = 45\n",
    "\n",
    "# collection of sync and assync plots\n",
    "sync_dic = {}\n",
    "async_dic ={}\n",
    "\n",
    "# max scaling values for upscaling correlation values with absorption spectrum\n",
    "max_scaling_value_sync = 0\n",
    "max_scaling_value_async = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define witdh of additionaly absorbtion correlation band\n",
    "width = 5\n",
    "\n",
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[215:300, 20]\n",
    "    \n",
    "    # sort out values with HT above 900\n",
    "    df = data_all[key].cd_df.loc[215:300, t_min:t_max]\n",
    "    \n",
    "    # add absorbance as extra row \n",
    "    for i in range(width):\n",
    "        df = df.append(data_all[key].absorb_df.loc[260, t_min:t_max], ignore_index = True)\n",
    "        ref[301+i] = data_all[key].absorb_df.loc[260, 20]\n",
    "    ref.index = np.arange(86 + width)\n",
    "    \n",
    "    # calculate\n",
    "    sync, assync = ana.correlation(df, ref_spec=[ref], center=False)\n",
    "    sync1, assync1 = ana.correlation(data_all[key].cd_df.loc[215:300, t_min:t_max], ref_spec=[data_all[key].cd_df.loc[215:300, 20]], scaling='pareto', center=False)\n",
    "        \n",
    "    # pareto scaling for CD-part\n",
    "    sync.loc[:85, :85] = sync1.to_numpy()\n",
    "    assync.loc[:85, :85] = assync1.to_numpy()\n",
    "    \n",
    "    # get the sacling the absorption values for sync, and assync and compare with max scaling value so far...\n",
    "    max_cd_value_sync = sync.abs().max().max()\n",
    "    max_abs_value_sync = sync.loc[86:].abs().max().max()\n",
    "    max_scaling_value_sync = (max_cd_value_sync / max_abs_value_sync)\n",
    "        \n",
    "    max_cd_value_async = assync.abs().max().max()\n",
    "    max_abs_value_async = assync.loc[86:].abs().max().max()\n",
    "    max_scaling_value_async = (max_cd_value_async / max_abs_value_async)\n",
    "        \n",
    "    print(max_scaling_value_sync, max_scaling_value_async)\n",
    "    # adding DataFrame to plot dics\n",
    "    sync_dic[key] = sync\n",
    "    async_dic[key] =  assync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max scaling values for upscaling correlation values with absorption spectrum\n",
    "max_scaling_value_sync = 23.01341899344675\n",
    "max_scaling_value_async = 34.14136793491423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sync_dic.keys():\n",
    "    max_cd_value = sync_dic[key].abs().max().max()\n",
    "    sync_dic[key].loc[86:] =  sync_dic[key].loc[86:] * max_scaling_value_sync\n",
    "    sync_dic[key].loc[:85,86:] = sync_dic[key].loc[:85,86:] * max_scaling_value_sync\n",
    "    plot.heatmap(sync_dic[key],  title=key, subtitle=[\"Synchronous Spectrum\", ], y_label=\"Wavelength 1 [nm]\", \n",
    "                 x_label=\"Wavelength 2 [nm]\", c_label=\"\", c_min=[-max_cd_value], c_max=[max_cd_value], hline=85, vline=85,\n",
    "                 contour_lines=[-0.8*max_cd_value,-0.5*max_cd_value, -0.3*max_cd_value, -0.15*max_cd_value, 0, 0.15*max_cd_value, 0.3*max_cd_value, 0.5*max_cd_value, 0.8*max_cd_value])\n",
    "    \n",
    "    max_cd_value = async_dic[key].abs().max().max()\n",
    "    async_dic[key].loc[86:] =  async_dic[key].loc[86:] * max_scaling_value_async\n",
    "    async_dic[key].loc[:85,86:] = async_dic[key].loc[:85,86:] * max_scaling_value_async\n",
    "    plot.heatmap( async_dic[key], title=key, subtitle=[ \"Asynchronous Spectrum\", ], y_label=\"Wavelength 1 [nm]\", \n",
    "                 x_label=\"Wavelength 2 [nm]\",  c_label=\"\", hline=85, vline=85,\n",
    "                 contour_lines=[-0.8*max_cd_value, -0.5*max_cd_value,  -0.3*max_cd_value, -0.15*max_cd_value, 0, 0.15*max_cd_value, 0.3*max_cd_value, \n",
    "                                0.5*max_cd_value, 0.8*max_cd_value] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-anger",
   "metadata": {},
   "source": [
    "### Tools for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wales",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Change 'key' to wanted measurement!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"GdmCl_2M\"\n",
    "key2 = \"GdmCl_2M_24h\"\n",
    "ref1 = data_all[key1].cd_df.loc[:, 20]\n",
    "ref2 = data_all[key2].cd_df.loc[:, 20]\n",
    "sync, assync = ana.correlation(data_all[key1].cd_df.loc[:, :45], data_all[key2].cd_df.loc[:, :45], scaling='pareto', ref_spec=[ref1, ref2], center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(sync, assync,  title=str(key1) + str(key2), subtitle=[\"Synchronous Spectrum\", \"Asynchronous Spectrum\"], x_min=[210, 210], y_min=[210, 210],\n",
    "                y_label= str(key1) + \" WL[nm]\", x_label= str(key2) + \" WL[nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-fiber",
   "metadata": {},
   "source": [
    "**Diagonal Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sync.to_numpy()\n",
    "diag =  pd.DataFrame(arr.diagonal(), index=sync.index)\n",
    "wave =  list(sync.index)[:-1]\n",
    "diff =  pd.DataFrame(np.diff(arr.diagonal()), index=wave)\n",
    "plot.mult_func([0], [diff.T, diag.T], baseline=True, x_label=\"wavelength [nm]\", subtitle=[\"Diagonal with differential\"], label=[\"CD Values\", \"Differential\"], x_min=210)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-halloween",
   "metadata": {},
   "source": [
    "**Line Analyis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength=247\n",
    "# adjust wavelength to shift line analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sync.loc[wavelength, :].to_numpy()\n",
    "df = pd.DataFrame(arr, index=sync.index).T\n",
    "diff = pd.DataFrame(np.diff(arr), index=list(sync.index)[:-1]).T\n",
    "plot.mult_func([0], [df, diff], x_label=\"wavelength [nm]\", baseline=True, x_min=210, subtitle=[\"Synchronous Line Analysis\"], label=[wavelength, \"derivative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-pound",
   "metadata": {},
   "source": [
    "**Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "willing-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\output.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-coordinator",
   "metadata": {},
   "source": [
    "create new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "happy-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(excel_path, mode='w') as writer:  \n",
    "\n",
    "                    comp2_conc_df.round(2).to_excel(writer, sheet_name=\"output \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-mills",
   "metadata": {},
   "source": [
    "Homgeneous Spectra Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste \n",
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M', 'GdmCl_2M_24h' , 'GdmCl_4M', 'GdmCl_6M', 'Urea_2M']\n",
    "t_min = 20\n",
    "t_max = 90\n",
    "\n",
    "\n",
    "\n",
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[:, 20]\n",
    "    # sort out values with HT above 900\n",
    "    df = data_all[key].cd_df\n",
    "    # calculate\n",
    "    sync1, assync1 = ana.correlation(df.loc[:,:45], scaling='pareto', ref_spec=[ref], center=False)\n",
    "    df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "    df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "    with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "                    df1.to_excel(writer, sheet_name=key  + \" sync\")\n",
    "                    df2.to_excel(writer, sheet_name=key  + \" async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-watershed",
   "metadata": {},
   "source": [
    "Heterogeneous Spectra Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste\n",
    "\n",
    "#plot_list = [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_2M',  'GdmCl_4M', 'GdmCl_6M']\n",
    "plot_list = [\"Control_0M\", 'Gdm2SO4_0.5M', 'Gdm2SO4_2M',  'Gdm2SO4_4M', 'Gdm2SO4_6M']\n",
    "anzahl = len(plot_list)\n",
    "t_min = 20 \n",
    "t_max = 90\n",
    "\n",
    "\n",
    "# calculation \n",
    "for i in range(anzahl):\n",
    "    for j in range(anzahl):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        df1 = data_all[plot_list[i]].cd_df\n",
    "        df2 = data_all[plot_list[j]].cd_df\n",
    "        ref1 = df1.loc[:, 20]\n",
    "        ref2 = df2.loc[:, 20]\n",
    "        sync1, assync1 = ana.correlation(df1.loc[:, :t_max], df2.loc[:, :t_max], scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "        df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "        df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "        with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "            df1.to_excel(writer, sheet_name=plot_list[i] + \" vs.  \" + plot_list[j]  + \" sync\")\n",
    "            df2.to_excel(writer, sheet_name=plot_list[i] + \" vs.  \" + plot_list[j]  + \" async\")\n",
    "            \n",
    "# extra calculation for 2M vs 2M_24h            \n",
    "\"\"\"df1 = data_all[\"GdmCl_2M\"].cd_df\n",
    "df2 = data_all[\"GdmCl_2M_24h\"].cd_df\n",
    "ref1 = df1.loc[:, 20]\n",
    "ref2 = df2.loc[:, 20]\n",
    "sync1, assync1 = ana.correlation(df1.loc[:, :t_max], df2.loc[:, :t_max], scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "df1 = sync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "df2 = assync1.loc[[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312],[212, 215, 218, 221, 223, 229, 247, 261, 265, 268, 274, 281, 284, 294, 305, 312]].round(3)\n",
    "with pd.ExcelWriter(excel_path, mode='a') as writer:  \n",
    "    df1.to_excel(writer, sheet_name=\"2M vs. 2M 24h sync\")\n",
    "    df2.to_excel(writer, sheet_name=\"2M vs. 2M 24h async\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = assync.loc[wavelength, :].to_numpy()\n",
    "df = pd.DataFrame(arr, index=assync.index).T\n",
    "diff = pd.DataFrame(np.diff(arr), index=list(assync.index)[:-1]).T\n",
    "plot.mult_func([0], [df, diff], x_label=\"wavelength [nm]\", baseline=True, x_min=210, subtitle=[\"synchronous Line Analysis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-invention",
   "metadata": {},
   "source": [
    "### Heterogenous Spectrum\n",
    "\n",
    "*with pareto scaling and Control Measurement as Reference*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_list = [\"Control_0M\", 'GdmCl_0.5M', 'GdmCl_2M',  'GdmCl_4M', 'GdmCl_6M']\n",
    "plot_list = [\"Control_0M\", 'Gdm2SO4_0.5M', 'Gdm2SO4_2M',  'Gdm2SO4_4M', 'Gdm2SO4_6M']\n",
    "anzahl = len(plot_list)\n",
    "t_min = 20 \n",
    "t_max = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(anzahl):\n",
    "    for j in range(anzahl):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        title = \"Heterogenoues 2D Correlation between \" + plot_list[i] + \" \" + plot_list[j]\n",
    "        df1 = data_all[plot_list[i]].cd_df\n",
    "        df2 = data_all[plot_list[j]].cd_df\n",
    "        ref1 = df1.loc[:, 20]\n",
    "        ref2 = df2.loc[:, 20]\n",
    "        sync1, assync1 = ana.correlation(df1, df2, scaling='pareto', ref_spec=[ref1, ref2], center=False)\n",
    "        sync2, assync2 = ana.correlation(df1, df2, scaling='auto', ref_spec=[ref1, ref2], center=False)\n",
    "        plot.heatmap(sync1, assync1, title=title, subtitle=[\"Synchronous Spectrum\", \"Asynchronous Spectrum\", \"Synchronous Spectrum\", \"Asynchronous Spectrum\"], x_min=[210, 210, 210, 210], y_min=[210, 210, 210, 210],\n",
    "                y_label= plot_list[i] + \" WL[nm]\", x_label= plot_list[j] + \" WL[nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-queue",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Perturbation-Correlation Moving-Window 2D Correlation Spectroscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-initial",
   "metadata": {},
   "source": [
    "*different window size can be choosen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spare-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M',  'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'Control_0M', 'GdmCl_0.5M', 'GdmCl_1M' ,  'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "friendly-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bcef2165c2499ca9fc9dac29799fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57769fa05bb5484aa71729f514cd82de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da8550deb2e410cbb9141f74069c936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e418dd646c450b8992511f92925abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb616e7bcf742d5984c4169690998f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c95143730c482aa3a740277e86d989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301eada4a4ce46a196a9e6454bb47821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75ccb7b483146f0ada14166ef8723d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f8e11299b5421f872e4e5087ffc0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc0d0508ccb4f19b1811bc021be0811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f94c1a6b9d413c96fcc4102313f552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff58571135a46c9946bda04d65f03c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in liste:\n",
    "    df = data_all[key].cd_df.loc[215:300, 20:]\n",
    "    max_cd_value = df.abs().max().max()\n",
    "    sync, assync, = ana.perturbation_moving_window(df, window_size=3)\n",
    "    plot.heatmap(sync, x_min=[215], x_max=[300], x_label=\"Temperature [°C]\", y_label=\"Wavelength [nm]\", \n",
    "                 c_label=\"\", hline=melt_T[key], c_min=[-0.8e8], c_max=[0.8e8], title=\"\", subtitle=[key],\n",
    "                contour_lines=[-0.7*max_cd_value, -0.4*max_cd_value,  -0.2*max_cd_value,  0, 0.2*max_cd_value, \n",
    "                                0.4*max_cd_value, 0.7*max_cd_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-hazard",
   "metadata": {},
   "source": [
    "### 2D Correlation of Null Space Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-secretary",
   "metadata": {},
   "source": [
    "*different projection_vectors/matrices can be choosen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste =  ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', \"Gdm2SO4_6M\", \"Control_0M\" ,'GdmCl_0.5M', 'GdmCl_2M' , 'GdmCl_4M', 'GdmCl_6M' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[:, 20]\n",
    "    \n",
    "    # create dynamic spectrum! and calculate projection\n",
    "    df = ana.projection_matrix(data_all[key].cd_df.subtract(ref, axis=0), row_min_max=[247], center=False)\n",
    "    plot.mult_func([264, 274, 281], [df], subtitle=[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[:, 20]\n",
    "    \n",
    "    # create dynamic spectrum! and calculate projection\n",
    "    df = ana.projection_matrix(data_all[key].cd_df.subtract(ref, axis=0), row_min_max=[247], center=False)\n",
    "    sync, assync = ana.correlation(df)\n",
    "            \n",
    "    plot.heatmap(sync, assync, x_min=[220, 220], y_min=[220,220], subtitle=[\"\"], title=str(key), c_max=[2e+20, 2e+20], c_min=[-1e+20,-1e+20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in liste:\n",
    "    # get reference\n",
    "    ref = data_all[key].cd_df.loc[:, 20]\n",
    "    \n",
    "    # create dynamic spectrum! and calculate projection\n",
    "    df = ana.projection_matrix(data_all[key].cd_df.subtract(ref, axis=0), row_min_max=[247], center=False)\n",
    "    \n",
    "     # sort out values with HT above 900\n",
    "    for wave in data_all[key].ht_df.index:\n",
    "        if data_all[key].ht_df.max(axis=1).loc[wave] >= 900:\n",
    "            df = df.drop(wave)\n",
    "    # calculate\n",
    "    sync1, assync1, = ana.correlation(df, ref_spec=[0])\n",
    "    # plot\n",
    "    plot.heatmap(sync1, assync1, title=str(key), subtitle=[\"Synchronous Spectrum\", \"Asynchronous Spectrum\"], y_label=\"wavelength [nm]\", \n",
    "                 x_label=\"wavenlength [nm]\", x_min=[220, 220], y_min=[220,220])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-community",
   "metadata": {},
   "source": [
    "## Sigmoid Fit and Melting Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph={}\n",
    "melt_T={}\n",
    "for key in data_all.keys():\n",
    "    fit, params, error = ana.sigmoid_fit(ana.normalize(data_all[key].cd_df))\n",
    "    x =  np.arange(20, 91, 0.1)\n",
    "    deriv = pd.DataFrame(ana.sigmoid_deriv(x, *params), index=x, columns=[\"deriv\"]).T\n",
    "    maximum = deriv.max(axis=1) \n",
    "    T = float(deriv.idxmax(axis=1))\n",
    "    maxi = pd.DataFrame({T:1}, index=[\"Maximum\"])\n",
    "    deriv = deriv.div(maximum, axis=0)\n",
    "    fit = pd.concat([fit, deriv], axis=0)\n",
    "    fit = pd.concat([fit, maxi], axis=0)\n",
    "    graph[key] = [fit]  \n",
    "    melt_T[key] = T\n",
    "plot.mult_func([247, \"fit\", \"deriv\", \"Maximum\"], *graph.values(),  title=\"Sigmoid-Fit and Derivative(adjusted)\",\n",
    "               subtitle=list(graph.keys()), marker=['x', '', '', 'x'], linestyle=[\"\",\"-\", \":\",\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-serve",
   "metadata": {},
   "source": [
    "Plot the melting Temperatures for the Gdm2SO4 and GdmCl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0., 0.5, 2., 4.]\n",
    "y = list(melt_T.values())[0:4]\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "\n",
    "y2 = [melt_T[\"Control_0M\"], melt_T[\"GdmCl_0.5M\"], melt_T[\"GdmCl_2M\"], melt_T[\"GdmCl_4M\"]]\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], title=\"Melting Temperature\", subtitle=[\"\"], x_label=\"Concentration[M]\", y_label=\"Temperature[K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-ethics",
   "metadata": {},
   "source": [
    "## Absorbance Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorbance = list(map(lambda x: data_all[x].absorb_df, list(data_all.keys())))\n",
    "for i in absorbance:\n",
    "    plot.heatmap(i, subtitle=tuple(data_all.keys()), title=\"Absorbance Values\", x_min=[260]*len(data_all), c_min=[0]*len(data_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    df = data_all[key].absorb_df\n",
    "    deriv_df = ana.derivative(df)*10\n",
    "    plot.mult_func([260], [df - df.min(axis=1).loc[260], deriv_df], subtitle=[key], linestyle=[\"-\",\":\"], marker=[\"x\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph={}\n",
    "melt_T={}\n",
    "error_a = {}\n",
    "error_b = {}\n",
    "coop={}\n",
    "elements = [\"Control_0M\", \"Gdm2SO4_0.5M\", \"Gdm2SO4_2M\", \"Gdm2SO4_4M\", \"Control_0M\", \"GdmCl_0.5M\", \"GdmCl_2M\", \"GdmCl_4M\" ]\n",
    "key = \"GdmSCN_0.5M\"\n",
    "fit, params, std = ana.sigmoid_fit(ana.normalize(data_all[key].absorb_df), wave=260, a_range=[0.2, 0.5])\n",
    "x =  np.arange(20, 91, 0.1)\n",
    "deriv = pd.DataFrame(ana.sigmoid_deriv(x, *params), index=x, columns=[\"deriv\"]).T\n",
    "maximum = deriv.max(axis=1) \n",
    "T = float(deriv.idxmax(axis=1))\n",
    "maxi = pd.DataFrame({T:1}, index=[\"Maximum\"])\n",
    "deriv = deriv.div(maximum, axis=0)\n",
    "fit = pd.concat([fit, deriv], axis=0)\n",
    "fit = pd.concat([fit, maxi], axis=0)\n",
    "graph[key] = [fit]  \n",
    "melt_T[key] = params[1]\n",
    "error_a[key] = std[0]\n",
    "error_b[key] = std[1]\n",
    "coop[key] = params[0] \n",
    "plot.mult_func([260, \"fit\", \"deriv\"], graph[key],  title=\"Sigmoid-Fit and Derivative(adjusted)\", subtitle=list(graph.keys()), marker=['x', '', '', 'x'], linestyle=[\"\",\"-\", \":\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph={}\n",
    "melt_T={}\n",
    "error_a = {}\n",
    "error_b = {}\n",
    "coop={}\n",
    "elements = [\"Control_0M\", \"Gdm2SO4_0.5M\", \"Gdm2SO4_2M\", \"Gdm2SO4_4M\", \"Control_0M\", \"GdmCl_0.5M\", \"GdmCl_2M\", \"GdmCl_4M\" ]\n",
    "for key in data_all.keys():\n",
    "    fit, params, std = ana.sigmoid_fit(ana.normalize(data_all[key].absorb_df), wave=260, a_range=[0.2, 0.5])\n",
    "    x =  np.arange(20, 91, 0.1)\n",
    "    deriv = pd.DataFrame(ana.sigmoid_deriv(x, *params), index=x, columns=[\"deriv\"]).T\n",
    "    maximum = deriv.max(axis=1) \n",
    "    T = float(deriv.idxmax(axis=1))\n",
    "    maxi = pd.DataFrame({T:1}, index=[\"Maximum\"])\n",
    "    deriv = deriv.div(maximum, axis=0)\n",
    "    fit = pd.concat([fit, deriv], axis=0)\n",
    "    fit = pd.concat([fit, maxi], axis=0)\n",
    "    graph[key] = [fit]  \n",
    "    melt_T[key] = params[1]\n",
    "    error_a[key] = std[0]\n",
    "    error_b[key] = std[1]\n",
    "    coop[key] = params[0] \n",
    "plot.mult_func([260, \"fit\", \"deriv\"], graph[\"GdmCl_4M\"],  title=\"Sigmoid-Fit and Derivative(adjusted)\", subtitle=list(graph.keys()), marker=['x', '', '', 'x'], linestyle=[\"\",\"-\", \":\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0., 0.5, 2., 4.]\n",
    "y = list(melt_T.values())[0:4]\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "\n",
    "y2 = [melt_T[\"Control_0M\"], melt_T[\"GdmCl_0.5M\"], melt_T[\"GdmCl_2M\"], melt_T[\"GdmCl_4M\"]]\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], error=error_b, title=\"Melting Temperature\",\n",
    "               subtitle=[\"\"], x_label=\"Concentration[M]\", y_label=\"Temperature[°C]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0., 0.5, 2., 4.]\n",
    "y = list(coop.values())[0:4]\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "\n",
    "y2 = [coop[\"Control_0M\"], coop[\"GdmCl_0.5M\"], coop[\"GdmCl_2M\"], coop[\"GdmCl_4M\"]]\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], error=error_a, title=\"Variance\",\n",
    "               subtitle=[\"\"], x_label=\"Concentration[M]\", y_label=\"Temperature[K^2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-foster",
   "metadata": {},
   "source": [
    "### LM Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[\"Control_0M\"].cd_df\n",
    "plot.mult_func([280], [df], swap=False, linestyle=[\"\"], marker=[\"X\"], x_label=\"Temperature [°C]\", subtitle=[\"\"], title=\"Control Measurement Hyperchromatic Shift\", label=[\"260 nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "sample = \"Control_0M\"\n",
    "melt_T = {}\n",
    "error_T = {}\n",
    "residual = pd.DataFrame(index=[\"R-Wert\"])\n",
    "for key in liste:\n",
    "    fit, params, params_error = ana.lm_fit(data_all[key].absorb_df, guess=[0.13, 0.36, 0.4])\n",
    "    melt_T[key] = params['xc']\n",
    "    error_T[key] = params_error\n",
    "    residual[key] = [1 - (np.sum(fit[\"residual\"]**2)/np.sum((fit[260] - fit[260].mean(axis=0))**2))]\n",
    "    plot.mult_func([260, \"fit\"], [fit], error={\"fit\": fit[\"error\"]}, swap=True, \n",
    "                   x_label=\"Temperature [°C]\", y_label=\"Absorbance [%]\", label=[\"data\", \"sigmoid fit\", 'melting temperature'], marker=['o', ''], linestyle=[\" \", \"-\"],\n",
    "                  subtitle=[\"Hyperchromatic shift\"], title=key, vertical_line=[params['xc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0., 0.5, 2., 4., 6.]\n",
    "y = list(melt_T.values())[0:5]\n",
    "\n",
    "y_error = list(error_T.values())[0:5]\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "error= {\"Gdm2SO4\":y_error}\n",
    "\n",
    "y2 = [melt_T[\"Control_0M\"], melt_T[\"GdmCl_0.5M\"], melt_T[\"GdmCl_2M\"], melt_T[\"GdmCl_4M\"], melt_T[\"GdmCl_6M\"]]\n",
    "y2_error = [error_T[\"Control_0M\"], error_T[\"GdmCl_0.5M\"], error_T[\"GdmCl_2M\"], error_T[\"GdmCl_4M\"], error_T[\"GdmCl_6M\"]]\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "error[\"GdmCl\"] = y2_error \n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], title=\"Melting Temperature\", subtitle=[\"\"], x_label=\"Concentration [M]\", y_label=\"Temperature [°C]\", error=error_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-charm",
   "metadata": {},
   "source": [
    "### Linear LM Fit for Melting Temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secure-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "melt_T = {}\n",
    "comp2_conc = {}\n",
    "liste = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_1M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_1M', 'GdmCl_2M', 'GdmCl_4M', 'GdmCl_6M',  'GdmSCN_0.5M', 'Urea_2M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "professional-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.7907e-06\n",
      "    reduced chi-square = 1.7907e-06\n",
      "    Akaike info crit   = -38.9945189\n",
      "    Bayesian info crit = -40.7972944\n",
      "[[Variables]]\n",
      "    m:   4.5476e-04 +/- 1.2389e-04 (27.24%) (init = 1)\n",
      "    y0:  0.45481350 +/- 0.01014723 (2.23%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.7600e-07\n",
      "    reduced chi-square = 3.7600e-07\n",
      "    Akaike info crit   = -43.6768616\n",
      "    Bayesian info crit = -45.4796371\n",
      "[[Variables]]\n",
      "    m:   9.8400e-05 +/- 4.3359e-05 (44.06%) (init = 1)\n",
      "    y0:  0.35534533 +/- 0.00134809 (0.38%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.4337e-05\n",
      "    reduced chi-square = 1.4337e-05\n",
      "    Akaike info crit   = -32.7538582\n",
      "    Bayesian info crit = -34.5566336\n",
      "[[Variables]]\n",
      "    m:   0.01386555 +/- 0.00106389 (7.67%) (init = 1)\n",
      "    y0: -0.46299055 +/- 0.06847845 (14.79%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b46a90c89949319e2f38f2c9306073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.0782e-06\n",
      "    reduced chi-square = 2.0782e-06\n",
      "    Akaike info crit   = -38.5478172\n",
      "    Bayesian info crit = -40.3505926\n",
      "[[Variables]]\n",
      "    m:   9.9431e-04 +/- 1.3347e-04 (13.42%) (init = 1)\n",
      "    y0:  0.45338000 +/- 0.01093152 (2.41%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.8240e-08\n",
      "    reduced chi-square = 3.8240e-08\n",
      "    Akaike info crit   = -50.5339750\n",
      "    Bayesian info crit = -52.3367505\n",
      "[[Variables]]\n",
      "    m:  -3.7950e-05 +/- 1.3828e-05 (36.44%) (init = 1)\n",
      "    y0:  0.38311617 +/- 4.2992e-04 (0.11%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.1274e-05\n",
      "    reduced chi-square = 2.1274e-05\n",
      "    Akaike info crit   = -31.5698926\n",
      "    Bayesian info crit = -33.3726681\n",
      "[[Variables]]\n",
      "    m:   0.01154933 +/- 0.00108715 (9.41%) (init = 1)\n",
      "    y0: -0.29609333 +/- 0.07288774 (24.62%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d777d924a9f747e890e4c9b80e616169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.4068e-06\n",
      "    reduced chi-square = 1.4068e-06\n",
      "    Akaike info crit   = -39.7183176\n",
      "    Bayesian info crit = -41.5210930\n",
      "[[Variables]]\n",
      "    m:   6.9760e-04 +/- 1.0981e-04 (15.74%) (init = 1)\n",
      "    y0:  0.43787800 +/- 0.00899409 (2.05%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 6.0423e-09\n",
      "    reduced chi-square = 6.0423e-09\n",
      "    Akaike info crit   = -56.0692821\n",
      "    Bayesian info crit = -57.8720575\n",
      "[[Variables]]\n",
      "    m:   3.1133e-04 +/- 5.2328e-06 (1.68%) (init = 1)\n",
      "    y0:  0.36192159 +/- 1.6495e-04 (0.05%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.962\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 9.5600e-07\n",
      "    reduced chi-square = 9.5600e-07\n",
      "    Akaike info crit   = -40.8773476\n",
      "    Bayesian info crit = -42.6801230\n",
      "[[Variables]]\n",
      "    m:   0.01294225 +/- 3.4569e-04 (2.67%) (init = 1)\n",
      "    y0: -0.40660292 +/- 0.02247684 (5.53%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0e707e190b4827974af7821ad8be56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.5906e-08\n",
      "    reduced chi-square = 3.5906e-08\n",
      "    Akaike info crit   = -50.7229390\n",
      "    Bayesian info crit = -52.5257145\n",
      "[[Variables]]\n",
      "    m:   8.9916e-04 +/- 1.7543e-05 (1.95%) (init = 1)\n",
      "    y0:  0.48147250 +/- 0.00143687 (0.30%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.3607e-09\n",
      "    reduced chi-square = 3.3607e-09\n",
      "    Akaike info crit   = -57.8292163\n",
      "    Bayesian info crit = -59.6319917\n",
      "[[Variables]]\n",
      "    m:  -3.1900e-05 +/- 4.0992e-06 (12.85%) (init = 1)\n",
      "    y0:  0.39800533 +/- 1.2745e-04 (0.03%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.0353e-04\n",
      "    reduced chi-square = 1.0353e-04\n",
      "    Akaike info crit   = -26.8226598\n",
      "    Bayesian info crit = -28.6254352\n",
      "[[Variables]]\n",
      "    m:   0.01283067 +/- 0.00239831 (18.69%) (init = 1)\n",
      "    y0: -0.35784967 +/- 0.16079432 (44.93%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bc955279aa4fdba023fc5cbfe8c104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 8.3314e-06\n",
      "    reduced chi-square = 8.3314e-06\n",
      "    Akaike info crit   = -34.3822637\n",
      "    Bayesian info crit = -36.1850391\n",
      "[[Variables]]\n",
      "    m:   0.00108697 +/- 2.6723e-04 (24.58%) (init = 1)\n",
      "    y0:  0.47829300 +/- 0.02188736 (4.58%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.4603e-08\n",
      "    reduced chi-square = 1.4603e-08\n",
      "    Akaike info crit   = -53.4220219\n",
      "    Bayesian info crit = -55.2247973\n",
      "[[Variables]]\n",
      "    m:  -8.1900e-05 +/- 8.5448e-06 (10.43%) (init = 1)\n",
      "    y0:  0.40401533 +/- 2.6567e-04 (0.07%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.9265e-05\n",
      "    reduced chi-square = 3.9265e-05\n",
      "    Akaike info crit   = -29.7313450\n",
      "    Bayesian info crit = -31.5341204\n",
      "[[Variables]]\n",
      "    m:   0.01529217 +/- 0.00147696 (9.66%) (init = 1)\n",
      "    y0: -0.52604750 +/- 0.09902231 (18.82%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09616c73a084468aa939ed162b295453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.5456e-07\n",
      "    reduced chi-square = 1.5456e-07\n",
      "    Akaike info crit   = -46.3438859\n",
      "    Bayesian info crit = -48.1466613\n",
      "[[Variables]]\n",
      "    m:   9.7671e-05 +/- 3.6398e-05 (37.27%) (init = 1)\n",
      "    y0:  0.42814550 +/- 0.00298114 (0.70%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.0837e-08\n",
      "    reduced chi-square = 1.0837e-08\n",
      "    Akaike info crit   = -54.3165974\n",
      "    Bayesian info crit = -56.1193728\n",
      "[[Variables]]\n",
      "    m:   6.9505e-04 +/- 7.3612e-06 (1.06%) (init = 1)\n",
      "    y0:  0.34496550 +/- 2.2887e-04 (0.07%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.8379e-07\n",
      "    reduced chi-square = 3.8379e-07\n",
      "    Akaike info crit   = -43.6153121\n",
      "    Bayesian info crit = -45.4180875\n",
      "[[Variables]]\n",
      "    m:   0.00953586 +/- 2.8678e-04 (3.01%) (init = 1)\n",
      "    y0: -0.17455871 +/- 0.01730598 (9.91%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6305bf333c6f4c3d8555aa935e58f73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.4203e-06\n",
      "    reduced chi-square = 2.4203e-06\n",
      "    Akaike info crit   = -38.0907081\n",
      "    Bayesian info crit = -39.8934835\n",
      "[[Variables]]\n",
      "    m:   5.8921e-04 +/- 1.4403e-04 (24.44%) (init = 1)\n",
      "    y0:  0.47127950 +/- 0.01179689 (2.50%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 4.6288e-08\n",
      "    reduced chi-square = 4.6288e-08\n",
      "    Akaike info crit   = -49.9609753\n",
      "    Bayesian info crit = -51.7637508\n",
      "[[Variables]]\n",
      "    m:  -5.2500e-06 +/- 1.5214e-05 (289.78%) (init = 1)\n",
      "    y0:  0.37982883 +/- 4.7301e-04 (0.12%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.3206e-06\n",
      "    reduced chi-square = 1.3206e-06\n",
      "    Akaike info crit   = -39.9080947\n",
      "    Bayesian info crit = -41.7108701\n",
      "[[Variables]]\n",
      "    m:   0.01375232 +/- 3.2289e-04 (2.35%) (init = 1)\n",
      "    y0: -0.44769232 +/- 0.02078323 (4.64%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ce9634e614275a8a51df9e2978a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.6650e-06\n",
      "    reduced chi-square = 1.6650e-06\n",
      "    Akaike info crit   = -39.2129467\n",
      "    Bayesian info crit = -41.0157221\n",
      "[[Variables]]\n",
      "    m:   3.8414e-04 +/- 1.1946e-04 (31.10%) (init = 1)\n",
      "    y0:  0.40393600 +/- 0.00978446 (2.42%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.3064e-08\n",
      "    reduced chi-square = 2.3064e-08\n",
      "    Akaike info crit   = -52.0508155\n",
      "    Bayesian info crit = -53.8535909\n",
      "[[Variables]]\n",
      "    m:   5.6070e-04 +/- 1.0739e-05 (1.92%) (init = 1)\n",
      "    y0:  0.32645100 +/- 3.3388e-04 (0.10%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 4.2211e-07\n",
      "    reduced chi-square = 4.2211e-07\n",
      "    Akaike info crit   = -43.3298655\n",
      "    Bayesian info crit = -45.1326410\n",
      "[[Variables]]\n",
      "    m:   0.00808508 +/- 1.8255e-04 (2.26%) (init = 1)\n",
      "    y0: -0.13512508 +/- 0.01174998 (8.70%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6856b8f173ad4f159e22a663c57538eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.2600e-08\n",
      "    reduced chi-square = 1.2600e-08\n",
      "    Akaike info crit   = -53.8645439\n",
      "    Bayesian info crit = -55.6673194\n",
      "[[Variables]]\n",
      "    m:   7.5220e-04 +/- 1.0392e-05 (1.38%) (init = 1)\n",
      "    y0:  0.41155400 +/- 8.5118e-04 (0.21%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 4.6464e-08\n",
      "    reduced chi-square = 4.6464e-08\n",
      "    Akaike info crit   = -49.9496009\n",
      "    Bayesian info crit = -51.7523763\n",
      "[[Variables]]\n",
      "    m:   7.3400e-05 +/- 1.5242e-05 (20.77%) (init = 1)\n",
      "    y0:  0.34197700 +/- 4.7389e-04 (0.14%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.0091e-06\n",
      "    reduced chi-square = 2.0091e-06\n",
      "    Akaike info crit   = -38.6492622\n",
      "    Bayesian info crit = -40.4520376\n",
      "[[Variables]]\n",
      "    m:   0.01345350 +/- 5.0114e-04 (3.72%) (init = 1)\n",
      "    y0: -0.43468634 +/- 0.03108146 (7.15%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6297b02908af4d79b7484bcda4e102d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 6.1866e-07\n",
      "    reduced chi-square = 6.1866e-07\n",
      "    Akaike info crit   = -42.1829637\n",
      "    Bayesian info crit = -43.9857391\n",
      "[[Variables]]\n",
      "    m:   5.7319e-04 +/- 7.2820e-05 (12.70%) (init = 1)\n",
      "    y0:  0.51707650 +/- 0.00596431 (1.15%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.1957e-07\n",
      "    reduced chi-square = 1.1957e-07\n",
      "    Akaike info crit   = -47.1139745\n",
      "    Bayesian info crit = -48.9167499\n",
      "[[Variables]]\n",
      "    m:  -7.6500e-06 +/- 2.4451e-05 (319.62%) (init = 1)\n",
      "    y0:  0.40523283 +/- 7.6022e-04 (0.19%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 5.4602e-07\n",
      "    reduced chi-square = 5.4602e-07\n",
      "    Akaike info crit   = -42.5576859\n",
      "    Bayesian info crit = -44.3604613\n",
      "[[Variables]]\n",
      "    m:   0.01560450 +/- 2.6125e-04 (1.67%) (init = 1)\n",
      "    y0: -0.44580933 +/- 0.01568086 (3.52%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298531a14698496c863c91f4e04fae4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.5005e-07\n",
      "    reduced chi-square = 2.5005e-07\n",
      "    Akaike info crit   = -44.9007022\n",
      "    Bayesian info crit = -46.7034777\n",
      "[[Variables]]\n",
      "    m:   5.1996e-04 +/- 4.6295e-05 (8.90%) (init = 1)\n",
      "    y0:  0.42067150 +/- 0.00379179 (0.90%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.7002e-07\n",
      "    reduced chi-square = 3.7002e-07\n",
      "    Akaike info crit   = -43.7249902\n",
      "    Bayesian info crit = -45.5277657\n",
      "[[Variables]]\n",
      "    m:   6.2980e-04 +/- 4.3013e-05 (6.83%) (init = 1)\n",
      "    y0:  0.35042833 +/- 0.00133732 (0.38%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 3.5883e-08\n",
      "    reduced chi-square = 3.5883e-08\n",
      "    Akaike info crit   = -50.7248713\n",
      "    Bayesian info crit = -52.5276467\n",
      "[[Variables]]\n",
      "    m:   0.00630233 +/- 4.4648e-05 (0.71%) (init = 1)\n",
      "    y0:  0.07963967 +/- 0.00236889 (2.97%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c012e1051c4c20a969462f0a922ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.8115e-05\n",
      "    reduced chi-square = 1.8115e-05\n",
      "    Akaike info crit   = -32.0521993\n",
      "    Bayesian info crit = -33.8549747\n",
      "[[Variables]]\n",
      "    m:   0.01084090 +/- 3.9404e-04 (3.63%) (init = 1)\n",
      "    y0: -0.02179150 +/- 0.03227375 (148.10%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.2161e-05\n",
      "    reduced chi-square = 1.2161e-05\n",
      "    Akaike info crit   = -33.2476759\n",
      "    Bayesian info crit = -35.0504513\n",
      "[[Variables]]\n",
      "    m:   0.00367720 +/- 2.4659e-04 (6.71%) (init = 1)\n",
      "    y0:  0.30347133 +/- 0.00766668 (2.53%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 1.2489e-06\n",
      "    reduced chi-square = 1.2489e-06\n",
      "    Akaike info crit   = -40.0755714\n",
      "    Bayesian info crit = -41.8783468\n",
      "[[Variables]]\n",
      "    m:   0.01765134 +/- 3.1400e-04 (1.78%) (init = 1)\n",
      "    y0: -0.46916534 +/- 0.02021113 (4.31%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18bdea6b1ba497bbb19f82d95f8ffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 2.4499e-07\n",
      "    reduced chi-square = 2.4499e-07\n",
      "    Akaike info crit   = -44.9619437\n",
      "    Bayesian info crit = -46.7647191\n",
      "[[Variables]]\n",
      "    m:   7.4131e-04 +/- 4.5825e-05 (6.18%) (init = 1)\n",
      "    y0:  0.44485300 +/- 0.00375328 (0.84%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.997\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 6\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 9.5938e-06\n",
      "    reduced chi-square = 9.5938e-06\n",
      "    Akaike info crit   = -33.9590294\n",
      "    Bayesian info crit = -35.7618048\n",
      "[[Variables]]\n",
      "    m:  -2.7950e-05 +/- 2.1902e-04 (783.60%) (init = 1)\n",
      "    y0:  0.36149050 +/- 0.00680951 (1.88%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -0.965\n",
      "[[Model]]\n",
      "    Model(linear)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 7\n",
      "    # data points      = 3\n",
      "    # variables        = 2\n",
      "    chi-square         = 9.5761e-08\n",
      "    reduced chi-square = 9.5761e-08\n",
      "    Akaike info crit   = -47.7800783\n",
      "    Bayesian info crit = -49.5828537\n",
      "[[Variables]]\n",
      "    m:   0.01497500 +/- 1.0941e-04 (0.73%) (init = 1)\n",
      "    y0: -0.45943567 +/- 0.00656690 (1.43%) (init = 0)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(m, y0) = -1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cffe7c98e8c450fa5b4e77826cfaf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in liste:\n",
    "\n",
    "    # fit three secitons\n",
    "    df =  data_all[key].absorb_df.loc[:,20:]\n",
    "    high_fit, high_params, high_std =  ana.lm_fit(df.iloc[:,-3:], f_type='linear')\n",
    "    low_fit, low_params, low_std =  ana.lm_fit(df.iloc[:,:3], f_type='linear')\n",
    "\n",
    "\n",
    "    # normalize absorbance values and get next 3 values to 0.5\n",
    "    df_norm = ana.normalize(df).loc[260, :]\n",
    "    df_sort = pd.DataFrame(df_norm.iloc[(df_norm-0.5).abs().argsort()[:3]], columns=[260])\n",
    "    # make linear fit\n",
    "    middle_fit, middle_params, middle_std = ana.lm_fit(df.loc[:, df_sort.index], f_type='linear')\n",
    "\n",
    "\n",
    "    # calculate cross of middle and median\n",
    "    melt_T[key] = ( ( (- high_params[\"y0\"] - low_params[\"y0\"]) / 2 ) + middle_params[\"y0\"] ) / ( ( (high_params[\"m\"] + low_params[\"m\"]) / 2 ) - middle_params[\"m\"] ) \n",
    "    # calculate error \n",
    "    teiler = ( ( (high_params[\"m\"] + low_params[\"m\"]) / 2 ) - middle_params[\"m\"] ) \n",
    "    nenner =  ( ( (- high_params[\"y0\"] - low_params[\"y0\"]) / 2 ) + middle_params[\"y0\"] ) \n",
    "    t_melt_error =  np.sqrt( (-0.5 * high_std[\"y0\"] / teiler)**2 + (-0.5 * low_std[\"y0\"] / teiler)**2 + (middle_std[\"y0\"] / teiler)**2\n",
    "                              + (nenner * 0.5 * high_std[\"m\"] / (teiler**2) )**2 + (nenner * 0.5 * low_std[\"m\"] / (teiler**2) )**2 + (nenner * -1 * middle_std[\"m\"] / (teiler**2) )**2)\n",
    "\n",
    "    \n",
    "    # make nice plot\n",
    "    plot_fit= pd.DataFrame(ana.linear(df.columns, *high_params.values()), columns=[\"high plateu\"], index=df.columns)\n",
    "    plot_fit[\"low plateu\"] = ana.linear(df.columns, *low_params.values())\n",
    "    plot_fit[\"middle\"] = ana.linear(df.columns, *middle_params.values())\n",
    "    plot_fit[\"Median\"] = 0.5*(plot_fit[\"high plateu\"] + plot_fit[\"low plateu\"])\n",
    "    comp2_conc[key] = (df.loc[260] - plot_fit[\"low plateu\"]) / (plot_fit[\"high plateu\"] - plot_fit[\"low plateu\"])\n",
    "\n",
    "    plot.mult_func([260, \"high plateu\", \"low plateu\", \"middle\", \"Median\"], [df, plot_fit.T], \n",
    "                   vertical_line=[melt_T[key]], marker=[\"X\", \"\", \"\", \"\", \"\"], linestyle=[\"--\", \":\", \":\", \"-.\", \"-.\"],\n",
    "                   y_scaling=True, y_min=[df.min(axis=1).loc[260] - 0.02], y_max=[df.max(axis=1).loc[260] + 0.02], \n",
    "                   title=key, subtitle=[\"\"], sec_ax=[df.min(axis=1).loc[260], df.max(axis=1).loc[260]], y_label=\"ssDNA Fraction [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coral-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Control_0M': 63.88046407740443, 'Gdm2SO4_0.5M': 64.52277673479793, 'Gdm2SO4_1M': 64.84295918577699, 'Gdm2SO4_2M': 64.33702771140105, 'Gdm2SO4_4M': 65.39728202507145, 'Gdm2SO4_6M': 61.39443444391862, 'GdmCl_0.5M': 64.87554508796475, 'GdmCl_1M': 65.7219345117269, 'GdmCl_2M': 62.22456104786192, 'GdmCl_4M': 59.194612694153875, 'GdmCl_6M': 53.41120314608025, 'GdmSCN_0.5M': 58.69785533338373, 'Urea_2M': 59.00866465738076}\n"
     ]
    }
   ],
   "source": [
    "print(melt_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fallen-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536a1b6c801c46038ab6c49017e90408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0., 0.5, 1., 2., 4., 6.]\n",
    "y =  [melt_T[\"Control_0M\"], melt_T[\"Gdm2SO4_0.5M\"], melt_T[\"Gdm2SO4_1M\"], melt_T[\"Gdm2SO4_2M\"], melt_T[\"Gdm2SO4_4M\"], melt_T[\"Gdm2SO4_6M\"]]\n",
    "\n",
    "graph1 = pd.DataFrame(y, index=x, columns=[\"Gdm2SO4\"]).T\n",
    "\n",
    "y2 = [melt_T[\"Control_0M\"], melt_T[\"GdmCl_0.5M\"], melt_T[\"GdmCl_1M\"], melt_T[\"GdmCl_2M\"], melt_T[\"GdmCl_4M\"], melt_T[\"GdmCl_6M\"]]\n",
    "\n",
    "graph2 = pd.DataFrame(y2, index=x, columns=[\"GdmCl\"] ).T\n",
    "\n",
    "graph = pd.concat([graph1, graph2], axis=0)\n",
    "plot.mult_func([\"Gdm2SO4\", \"GdmCl\"], [graph], title=\"Melting Temperature\", subtitle=[\"\"], \n",
    "               x_label=\"Concentration [M]\", y_label=\"Temperature [°C]\", label=[r'$Gdm_{2}SO_{4}$',  r\"$GdmCl$ \"],\n",
    "               marker=[\"X\",\"o\"], linestyle=[\"-.\", \"-\",], backgroundcolor='#FDEADA', colors=['midnightblue',  'royalblue']\n",
    "              )\n",
    "               #error={\"Gdm2SO4\":y_error, \"GdmCl\": y2_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-commissioner",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-hostel",
   "metadata": {},
   "source": [
    "# TD Calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-chrome",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Steps after Mergny, J.-L., & Lacroix, L. (2003). Analysis of Thermal Melting Curves. In OLIGONUCLEOTIDES (Vol. 13). www.liebertpub.com\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-accordance",
   "metadata": {},
   "source": [
    "**Hypochromatic Shift at 260nm  wit Low and High Plateau Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = data_all[\"Control_0M\"].absorb_df\n",
    "low_fit, params_lowfit = ana.lm_fit(raw[[20,30,40]], f_type='linear', guess=[0.0001, 0.35])\n",
    "high_fit, params_highfit = ana.lm_fit(raw[[70, 80,90]], f_type='linear', guess=[0.0001, 0.48])\n",
    "sig_fit, params_sigfit = ana.lm_fit(raw, f_type='s1', guess=[0.2, 0.35, 0.5, 63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-intention",
   "metadata": {},
   "source": [
    "**Calculating Fraction Folded with High Plateu adjusted manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treated = pd.DataFrame(raw.loc[260])\n",
    "data_treated[\"low_fit\"] = ana.linear(np.array(raw.columns), *params_lowfit.values())\n",
    "data_treated[\"high_fit\"] = ana.linear(np.array(raw.columns), 0.0004495999948082116, 0.45451300041966917)\n",
    "data_treated[\"intermediate\"] = 0.5*(data_treated[\"low_fit\"] + data_treated[\"high_fit\"])\n",
    "data_treated[\"fit\"] = sig_fit[\"fit\"]\n",
    "data_treated[\"baseline_fit\"] = (data_treated[\"high_fit\"] - data_treated[260])/(data_treated[\"high_fit\"] - data_treated[\"low_fit\"])\n",
    "data_treated[\"normed_data\"] = 1- ana.normalize(raw).loc[260].to_numpy()\n",
    "data_treated[\"log_fit\"] = 1 - ana.normalize(data_treated)[\"fit\"]\n",
    "plot.mult_func([260, \"low_fit\", \"high_fit\", \"intermediate\", \"fit\"], [data_treated.T], subtitle=[\"\"], title=\"Hypochromatic shift with Plaetau Fits\", y_label=\"Absorbance at 260nm\")\n",
    "plot.mult_func([\"baseline_fit\", \"normed_data\", \"log_fit\"], [data_treated.T], subtitle=[\"\"],  title=\"Fraction folded calculated by Plateu fits and Normalization\", y_label=\"Fraction folded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-emergency",
   "metadata": {},
   "source": [
    "**calulate K and ln K for different methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total = 40 * (10**-9) # # total strand concentration in molar\n",
    "\n",
    "# get K and ln K\n",
    "base_method = pd.DataFrame(data_treated[\"baseline_fit\"].to_numpy(), index=[20,30,40,45,50,56,56,58,60,62,64,67,70,75,80, 90], columns=[\"theta\"])\n",
    "base_method['theta'] = base_method['theta'].astype(float)\n",
    "\n",
    "# here equation depending on reaction type, choosen: Bimolecular, complementary strand types\n",
    "base_method[\"K\"] = (base_method[\"theta\"])/(c_total*((1 - base_method[\"theta\"])**2))\n",
    "base_method['ln K'] = np.log(base_method['K'])\n",
    "\n",
    "# select values in confidence values 0.1 < theta < 0.9\n",
    "base_method  = base_method.loc[60:70]\n",
    "# change celsius to kelvin\n",
    "base_method = base_method.set_index(1/(base_method.index + 273.15))\n",
    "\n",
    "# make linear fit and plot\n",
    "enthalpy_base, params_base = ana.lm_fit(base_method.T, wave=\"ln K\", f_type='linear', guess=[80000, -2])\n",
    "error = {\"fit\" : enthalpy_base[\"error\"].to_numpy()}\n",
    "plot.mult_func([\"ln K\", \"fit\"], [enthalpy_base.T], error=error, x_label=\"1/T [1/Kelvin]\", y_label=\"ln K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total = 40 * (10**-9) # # total strand concentration in molar\n",
    "\n",
    "# get K and ln K\n",
    "normed_method = pd.DataFrame(data_treated[\"normed_data\"].to_numpy(), index=[20,30,40,45,50,56,56,58,60,62,64,67,70,75,80, 90], columns=[\"theta\"])\n",
    "normed_method['theta'] = normed_method['theta'].astype(float)\n",
    "\n",
    "# here equation depending on reaction type, choosen: Bimolecular, complementary strand types\n",
    "normed_method[\"K\"] = (normed_method[\"theta\"])/(c_total*((1 - normed_method[\"theta\"])**2))\n",
    "normed_method['ln K'] = np.log(normed_method['K'])\n",
    "\n",
    "# select values in confidence values 0.1 < theta < 0.9\n",
    "normed_method  = normed_method.loc[60:70]\n",
    "# change celsius to kelvin\n",
    "normed_method = normed_method.set_index(1/(normed_method.index + 273.15))\n",
    "\n",
    "# make linear fit and plot\n",
    "enthalpy_normed, params_norm = ana.lm_fit(base_method.T, wave=\"ln K\", f_type='linear', guess=[80000, -2])\n",
    "error = {\"fit\" : enthalpy_normed[\"error\"].to_numpy()}\n",
    "plot.mult_func([\"ln K\", \"fit\"], [enthalpy_normed.T], error=error, x_label=\"1/T [1/Kelvin]\", y_label=\"ln K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total = 40 * (10**-9) # # total strand concentration in molar\n",
    "\n",
    "# get K and ln K\n",
    "fit_method = pd.DataFrame(data_treated[\"log_fit\"].to_numpy(), index=[20,30,40,45,50,56,56,58,60,62,64,67,70,75,80, 90], columns=[\"theta\"])\n",
    "fit_method['theta'] = fit_method['theta'].astype(float)\n",
    "\n",
    "# here equation depending on reaction type, choosen: Bimolecular, complementary strand types\n",
    "fit_method[\"K\"] = (fit_method[\"theta\"])/(c_total*((1 - fit_method[\"theta\"])**2))\n",
    "fit_method['ln K'] = np.log(fit_method['K'])\n",
    "\n",
    "# select values in confidence values 0.1 < theta < 0.9\n",
    "fit_method  = fit_method.loc[60:70]\n",
    "# change celsius to kelvin\n",
    "fit_method = fit_method.set_index(1/(fit_method.index + 273.15))\n",
    "\n",
    "# make linear fit and plot\n",
    "enthalpy_fit, params_fit = ana.lm_fit(fit_method.T, wave=\"ln K\", f_type='linear', guess=[80000, -2])\n",
    "error = {\"fit\" : enthalpy_fit[\"error\"].to_numpy()}\n",
    "plot.mult_func([\"ln K\", \"fit\"], [enthalpy_fit.T], error=error, x_label=\"1/T [1/Kelvin]\", y_label=\"ln K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-kidney",
   "metadata": {},
   "source": [
    "**Calculate Entropy and Enthalpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "enthalpy = pd.DataFrame([\"H [kJ/mol]\", \"H [kcal/mol]\", \"S [kJ/mol*K]\", \"S [kcal/mol*K]\"], columns=[\"units\"])\n",
    "enthalpy = enthalpy.set_index(\"units\")\n",
    "\n",
    "# for base method\n",
    "m, y0 = params_base.values()\n",
    "delta_H = -m * 8.3145\n",
    "delta_S = y0 * 8.3145\n",
    "enthalpy[\"base\"] = [delta_H*10**(-3), delta_H*0.2390057*10**(-3), delta_S*10**(-3), delta_S*0.2390057*10**(-3)]\n",
    "\n",
    "# for normed method\n",
    "m, y0 = params_norm.values()\n",
    "delta_H = -m * 8.3145\n",
    "delta_S = y0 * 8.3145\n",
    "enthalpy[\"norm\"] = [delta_H*10**(-3), delta_H*0.2390057*10**(-3), delta_S*10**(-3), delta_S*0.2390057*10**(-3)]\n",
    "\n",
    "# for fit method\n",
    "m, y0 = params_fit.values()\n",
    "delta_H = -m * 8.3145\n",
    "delta_S = y0 * 8.3145\n",
    "enthalpy[\"fit\"] = [delta_H*10**(-3), delta_H*0.2390057*10**(-3), delta_S*10**(-3), delta_S*0.2390057*10**(-3)]\n",
    "\n",
    "print(enthalpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-thursday",
   "metadata": {},
   "source": [
    "## Derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv = ana.derivative(data_all[\"Control_0M\"].absorb_df)\n",
    "data = data_all[\"Control_0M\"].absorb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([260], [data], [deriv], title= \"Hypochromatic shift\", subtitle=[\"Absolute value\", \"interpolated derivative\"], label=[\"\"], y_label=\"Absorbance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-tobago",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "annoying-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp2_conc_df = pd.DataFrame(index=data_all[\"Control_0M\"].t_list)\n",
    "for key in comp2_conc:\n",
    "    comp2_conc_df = pd.merge(comp2_conc_df, comp2_conc[key].to_frame(), how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "clean-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Control_0M  Gdm2SO4_0.5M  Gdm2SO4_1M  Gdm2SO4_2M  Gdm2SO4_4M  Gdm2SO4_6M  \\\n",
      "20   -0.002348      0.000878   -0.000397    0.000232   -0.000505    0.000597   \n",
      "30    0.004545     -0.001577    0.000725   -0.000425    0.000902   -0.001303   \n",
      "40   -0.002201      0.000716         NaN    0.000196   -0.000408    0.000717   \n",
      "41         NaN           NaN   -0.000329         NaN         NaN         NaN   \n",
      "45    0.001261      0.004520   -0.002470    0.004676    0.004675   -0.006639   \n",
      "50    0.011797      0.012885   -0.000191    0.008865    0.013364   -0.012174   \n",
      "53    0.029407           NaN    0.006428    0.020166    0.022450    0.000676   \n",
      "56    0.038453      0.031132    0.011403         NaN         NaN    0.020848   \n",
      "58    0.052477      0.045552    0.020060    0.040787    0.042097         NaN   \n",
      "59         NaN           NaN         NaN         NaN         NaN    0.050372   \n",
      "60    0.107784      0.085014         NaN    0.065898    0.062964    0.220281   \n",
      "61         NaN           NaN    0.094928         NaN         NaN         NaN   \n",
      "62    0.274632      0.231325         NaN    0.159282    0.137280    0.623533   \n",
      "63         NaN           NaN    0.275423         NaN         NaN         NaN   \n",
      "64    0.538402      0.443734         NaN    0.441756    0.344227         NaN   \n",
      "65         NaN           NaN    0.511427         NaN         NaN    1.023988   \n",
      "67    0.833723      0.723716    0.767370    0.783315    0.688869    1.239448   \n",
      "70    0.948120      0.912259    0.926045    0.944359    0.919698    1.123478   \n",
      "75    0.994332      0.994782    0.993958    0.999339    0.990473    1.005476   \n",
      "80    1.008384      1.007562    1.008900    1.000962    1.013793    0.991093   \n",
      "90    0.997281      0.997639    0.997137    0.999697    0.995702    1.003572   \n",
      "\n",
      "    GdmCl_0.5M  GdmCl_1M  GdmCl_2M  GdmCl_4M  GdmCl_6M  GdmSCN_0.5M   Urea_2M  \n",
      "20   -0.000850  0.000838  0.001058  0.001143 -0.003649    -0.007823  0.012805  \n",
      "30    0.001607 -0.001718 -0.001957 -0.002184  0.007419     0.025802 -0.023760  \n",
      "40   -0.000762  0.000880  0.000910  0.001045 -0.003771    -0.036773  0.011079  \n",
      "41         NaN       NaN       NaN       NaN       NaN          NaN       NaN  \n",
      "45    0.001662 -0.005788  0.004474  0.008968  0.010684    -2.552077  0.033915  \n",
      "50    0.009059 -0.004020  0.016886  0.024294  0.197073     0.510558  0.044276  \n",
      "53         NaN -0.007076       NaN  0.044785  0.465842     0.417032       NaN  \n",
      "56    0.024981 -0.003908  0.046934  0.147548  0.730136     0.392750  0.138165  \n",
      "58    0.036168 -0.001139  0.094824  0.372157  0.847633     0.435690  0.383800  \n",
      "59         NaN       NaN       NaN       NaN       NaN          NaN       NaN  \n",
      "60    0.069952  0.007026  0.231757  0.588233  0.918072     0.585378  0.613840  \n",
      "61         NaN       NaN       NaN       NaN       NaN          NaN       NaN  \n",
      "62    0.193977  0.078926  0.484139  0.788672       NaN     0.784077  0.832695  \n",
      "63         NaN       NaN       NaN       NaN  0.941952          NaN       NaN  \n",
      "64    0.416191  0.293980  0.699737  0.902720  0.973237     0.920436  0.936822  \n",
      "65         NaN       NaN       NaN       NaN       NaN          NaN       NaN  \n",
      "67    0.714984  0.651400  0.913378  0.955612  0.982625     1.055352       NaN  \n",
      "70    0.919140  0.889399  0.975225  0.989715  0.996795          NaN  0.990985  \n",
      "75    0.993887  0.989264  0.999502  0.997295  0.995689     1.010730  0.998124  \n",
      "80    1.008973  1.016328  1.000727  1.003984  1.006524     0.986231  1.002739  \n",
      "90    0.997132  0.994401  0.999770  0.998719  0.997786     1.003561  0.999133  \n"
     ]
    }
   ],
   "source": [
    "comp2_conc_df.columns = comp2_conc.keys()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'GdmCl_2M'\n",
    "# get reference\n",
    "ref = data_all[key].cd_df.loc[215:300, 20]\n",
    "    \n",
    "# sort out values with HT above 900\n",
    "df = data_all[key].cd_df.loc[215:300]\n",
    "    \n",
    "# calculate\n",
    "sync, assync = ana.correlation(df, ref_spec=[ref], scaling='pareto', center=False)\n",
    "sync1, assync1 = ana.correlation(df, ref_spec=[ref], scaling='auto', center=False)\n",
    "         \n",
    "plot.heatmap(sync, sync1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_1 = np.array(data_all[\"GdmCl_2M\"].t_list) - np.array(data_all[\"GdmCl_2M\"].t_list_exact)\n",
    "std = std_1**2\n",
    "std_2 = np.sqrt(np.sum(std))\n",
    "print(std_2, std, std_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    print(data_all[key].std/1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[key].absorb_df\n",
    "df_sort = pd.DataFrame(df_norm.iloc[(df_norm-0.5).abs().argsort()[:3]], columns=[260])\n",
    "# make linear fit\n",
    "fit, params, params_error = ana.lm_fit(df_sort.T, f_type='linear')\n",
    "\n",
    "std = data_all[key].std / (data_all[key].cd_df.max(axis=1).loc[247] - data_all[key].cd_df.min(axis=1).loc[247])\n",
    "fit_hoch, hoch, pe = ana.lm_fit(df_sort.T + std, f_type='linear')\n",
    "fit_tief , tief, pe  = ana.lm_fit(df_sort.T - std, f_type='linear')\n",
    "\n",
    "\n",
    "# calulate melting temperature\n",
    "melt_T[key] = (0.5 - params['y0'])/params['m']\n",
    "error_T[key] = ((0.5 - hoch['y0'])/hoch['m']) - ((0.5 - tief['y0'])/tief['m'])\n",
    "print(melt_T[key], error_T[key],std*2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['Control_0M', 'Gdm2SO4_0.5M', 'Gdm2SO4_2M', 'Gdm2SO4_4M', 'Gdm2SO4_6M', 'GdmCl_0.5M', 'GdmCl_2M', 'GdmCl_4M', 'GdmCl_6M' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    print(key, \"\\t\", data_all[key].dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_min = 300\n",
    "wave_max =330\n",
    "\n",
    "for key in liste:\n",
    "    df = data_all[key].cd_df\n",
    "    \n",
    "    \n",
    "    ht =  data_all[key].ht_df\n",
    "    ht_max = ht.max(axis=1)\n",
    "    \n",
    "    for i in ht_max.index:\n",
    "        if ht_max.loc[i] >= 800:\n",
    "            print(i)\n",
    "    df_std = df.loc[wave_min:wave_max].std(axis=0)\n",
    "    sync, assync = ana.correlation(df)\n",
    "    #print(key, \": \\t \\t \", '{:.2e}'.format(np.sqrt(np.max(np.diag(sync.loc[wave_min:wave_max, wave_min:wave_max])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([280], [data_all['Control_0M'].cd_df, data_all['GdmCl_0.5M'].cd_df, data_all['GdmCl_2M'].cd_df, data_all['GdmCl_4M'].cd_df, data_all['GdmCl_6M'].cd_df],\n",
    "               marker=[\"\",\"\",\"\",\"\",\"\",\"\"], linestyle=[\":\",\":\",\":\",\":\",\":\",\":\"], label=[\"0M\", \"0.5M\", \"2M\", \"4M\", \"6M\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-function",
   "metadata": {},
   "source": [
    "**Beers Law**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    absorbance = data_all[key].absorb_df.loc[260, 20]\n",
    "    df = data_all[key].cd_df\n",
    "    \n",
    "    conc_ds =  absorbance/(0.02*0.1) #[µg/mL]\n",
    "    molar = conc_ds * 10**(-6) / (4472760.4 * 10**(-3)) #[mol/l]\n",
    "    df_norm = 100 * df / (molar * 0.1)\n",
    "    print(key, \":  \\t\", molar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_all.keys():\n",
    "    plot.mult_func([280], [data_all[key].cd_df], subtitle=[key], y_scaling=True, y_max=[3.85], y_min=[1.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # put second y_axis for \"GdmCl_0.5M\" normed\n",
    "        # function to bring back values\n",
    "        def expand_back(y):\n",
    "            return y * (0.523893 - 0.379531) + 0.379531\n",
    "        # inverse function\n",
    "        def norm(y):\n",
    "            return (y - 0.379531) / (0.523893 - 0.379531)\n",
    "\n",
    "        # put axis and label\n",
    "        secax = ax.secondary_yaxis('right', functions=(expand_back, norm), fontsize=16)\n",
    "        secax.set_ylabel('Absorption [%]', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[\"Control_0M\"].cd_df\n",
    "mean = df.mean(axis=1)\n",
    "var =  df.var(axis=1)\n",
    "dyn = df.subtract(mean, axis=0)\n",
    "\n",
    "col = dyn.columns \n",
    "idx = dyn.index\n",
    "m = len(col)\n",
    "n =len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1 =  247\n",
    "wave2 = 260\n",
    "i = 20\n",
    "\n",
    "print(np.sum((dyn.loc[wave1, :]/mean[wave1] - dyn.loc[wave2, :]/mean[wave2]) * col) * np.sqrt(var.loc[wave1]*var.loc[wave2])/(m*(m-1)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assync = pd.DataFrame(np.zeros((n,n)), index=idx, columns=idx)\n",
    "\n",
    "for j in idx:\n",
    "    for k in idx:\n",
    "        assync.loc[j,k] = np.sum((dyn.loc[j, :]/mean[j] - dyn.loc[k, :]/mean[k]) * col) * np.sqrt(var.loc[j]*var.loc[k])/(m*(m-1))\n",
    "print(assync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(assync, x_min=[220], y_min=[220])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-shuttle",
   "metadata": {},
   "source": [
    "# Parafak Ethanol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-absolute",
   "metadata": {},
   "source": [
    "## *setting up the Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-spouse",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (11,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-combination",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Daniel:\n",
    "#path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "\n",
    "# My Path:\n",
    "path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\Ethanol\"\n",
    "datalist = os.listdir(path)\n",
    "print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_all = {}\n",
    "for i in range(len(datalist)):\n",
    "    data_all[datalist[i]] = cdata.CData(os.path.join(path, datalist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  data_all[\"Control_0%\"].cd_df\n",
    "df = df.rename(columns={-1:\"0%\"})\n",
    "df[\"50%\"] =  (data_all[\"Ethanol_50%\"].cd_df.loc[:,-1])\n",
    "df[\"nach\"] =  (data_all[\"Ethanol_50%_nachTest\"].cd_df.loc[:,-1])\n",
    "df[\"vor\"] =  (data_all[\"Ethanol_50%_vorTest\"].cd_df.loc[:,-1])\n",
    "df[\"50% real\"] =  (data_all[\"Ethanol_50%_real\"].cd_df.loc[:,-1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func(['0%', 'vor', 'nach', '50%', \"50% real\" ], [df], swap=True, marker=[\"\", \"\", \"\", \"\", \"\"], x_label=\"Wavelengt [nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-richmond",
   "metadata": {},
   "source": [
    "# Salmon testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-closer",
   "metadata": {},
   "source": [
    "## setting up the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the `widget` backend.\n",
    "# This requires jupyter-matplotlib a.k.a. ipympl.\n",
    "# ipympl can be install via pip or conda.\n",
    "%matplotlib widget\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Output\n",
    "import matplotlib\n",
    "import openpyxl\n",
    "\n",
    "from scipy import integrate\n",
    "import lmfit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analise as ana\n",
    "import cdata \n",
    "import hotznplots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-stomach",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Print always whole DataFrames\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of display.max_rows is 10 i.e. at max 10 rows will be printed.\n",
    "# Set it None to display all rows in the dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-vocabulary",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Get the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Daniel:\n",
    "#path = \"F:\\\\HZDR\\\\CD_data\"\n",
    "\n",
    "# My Path:\n",
    "path = \"C:\\\\Users\\\\crazy\\\\Mega\\\\Uni\\\\Masterarbeit\\\\Projekt\\\\Data\\\\CD_data\\\\Salmon Testes\"\n",
    "datalist_salmon = os.listdir(path)\n",
    "print(datalist_salmon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in one dictionary with foldernames as names\n",
    "data_salmon = {}\n",
    "for i in range(len(datalist_salmon)):\n",
    "    data_salmon[datalist_salmon[i]] = cdata.CData(os.path.join(path, datalist_salmon[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_salmon.keys():\n",
    "    absorbance = data_salmon[key].absorb_df.loc[260, 20]\n",
    "    df = data_salmon[key].cd_df\n",
    "    \n",
    "    conc_ds =  absorbance/(0.02*0.1*(10**3)) #[mg/mL]\n",
    "    print(key, \":  \\t\", conc_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_salmon.keys():\n",
    "    plot.mult_func([260], [data_salmon[key].absorb_df], subtitle=[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_salmon[\"Control_0M_continous\"].t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mult_func([20, 40, 60, 80], [data_salmon['Control_0M_continous'].cd_df], swap=True, baseline=True, marker=[\"\",\"\",\"\",\"\"], subtitle=[\"Salmon Control\"], linestyle=[\"-\",\":\", \":\", \"-\"], x_min=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-promotion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
